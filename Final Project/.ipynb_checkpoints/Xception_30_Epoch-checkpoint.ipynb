{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xception', 'imet-2019-fgvc6']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from keras.utils import Sequence\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "SIZE = 256\n",
    "NUM_CLASSES = 1103\n",
    "beta_f2=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../input/imet-2019-fgvc6/train/'\n",
    "data = pd.read_csv('../input/imet-2019-fgvc6/train.csv')\n",
    "\n",
    "train_dataset_info = []\n",
    "for name, labels in zip(data['id'], data['attribute_ids'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 2.0\n",
    "epsilon = K.epsilon()\n",
    "def focal_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = K.pow(1-pt, gamma) * CE\n",
    "    loss = K.sum(FL, axis=1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "#     y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), F2_THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f2 = (1+beta_f2**2)*p*r / (p*beta_f2**2 + r + K.epsilon())\n",
    "    f2 = tf.where(tf.is_nan(f2), tf.zeros_like(f2), f2)\n",
    "    return K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "class data_generator(Sequence):\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)   \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                    \n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "    def create_valid(dataset_info, batch_size, shape, augument=False):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            # dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)   \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image = cv2.imread(path+'.png')\n",
    "        image = cv2.resize(image, (SIZE, SIZE))\n",
    "        return image\n",
    "\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=(-15,15)),\n",
    "                iaa.Crop(px=(0, 16)),\n",
    "                iaa.Affine(shear=(-5, 5)),\n",
    "                iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "                iaa.Fliplr(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference link: https://gist.github.com/drscotthawley/d1818aabce8d1bf082a6fb37137473ae\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "def get_1cycle_schedule(lr_max=1e-3, n_data_points=8000, epochs=200, batch_size=40, verbose=0):          \n",
    "    \"\"\"\n",
    "    Creates a look-up table of learning rates for 1cycle schedule with cosine annealing\n",
    "    See @sgugger's & @jeremyhoward's code in fastai library: https://github.com/fastai/fastai/blob/master/fastai/train.py\n",
    "    Wrote this to use with my Keras and (non-fastai-)PyTorch codes.\n",
    "    Note that in Keras, the LearningRateScheduler callback (https://keras.io/callbacks/#learningratescheduler) only operates once per epoch, not per batch\n",
    "      So see below for Keras callback\n",
    "\n",
    "    Keyword arguments:\n",
    "    lr_max            chosen by user after lr_finder\n",
    "    n_data_points     data points per epoch (e.g. size of training set)\n",
    "    epochs            number of epochs\n",
    "    batch_size        batch size\n",
    "    Output:  \n",
    "    lrs               look-up table of LR's, with length equal to total # of iterations\n",
    "    Then you can use this in your PyTorch code by counting iteration number and setting\n",
    "          optimizer.param_groups[0]['lr'] = lrs[iter_count]\n",
    "    \"\"\"\n",
    "    if verbose > 0:\n",
    "        print(\"Setting up 1Cycle LR schedule...\")\n",
    "    pct_start, div_factor = 0.3, 25.        # @sgugger's parameters in fastai code\n",
    "    lr_start = lr_max/div_factor\n",
    "    lr_end = lr_start/1e4\n",
    "    n_iter = (n_data_points * epochs // batch_size) + 1    # number of iterations\n",
    "    a1 = int(n_iter * pct_start)\n",
    "    a2 = n_iter - a1\n",
    "\n",
    "    # make look-up table\n",
    "    lrs_first = np.linspace(lr_start, lr_max, a1)            # linear growth\n",
    "    lrs_second = (lr_max-lr_end)*(1+np.cos(np.linspace(0,np.pi,a2)))/2 + lr_end  # cosine annealing\n",
    "    lrs = np.concatenate((lrs_first, lrs_second))\n",
    "    return lrs\n",
    "\n",
    "\n",
    "class OneCycleScheduler(Callback):\n",
    "    \"\"\"My modification of Keras' Learning rate scheduler to do 1Cycle learning\n",
    "       which increments per BATCH, not per epoch\n",
    "    Keyword arguments\n",
    "        **kwargs:  keyword arguments to pass to get_1cycle_schedule()\n",
    "        Also, verbose: int. 0: quiet, 1: update messages.\n",
    "\n",
    "    Sample usage (from my train.py):\n",
    "        lrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=X_train.shape[0],\n",
    "        epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OneCycleScheduler, self).__init__()\n",
    "        self.verbose = kwargs.get('verbose', 0)\n",
    "        self.lrs = get_1cycle_schedule(**kwargs)\n",
    "        self.iteration = 0\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = self.lrs[self.iteration]\n",
    "        K.set_value(self.model.optimizer.lr, lr)         # here's where the assignment takes place\n",
    "        if self.verbose > 0:\n",
    "            print('\\nIteration %06d: OneCycleScheduler setting learning '\n",
    "                  'rate to %s.' % (self.iteration, lr))\n",
    "        self.iteration += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):  # this is unchanged from Keras LearningRateScheduler\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "        self.iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = Xception(include_top=False,\n",
    "                   weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    base_model.load_weights('../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "#     x = Conv2D(32, kernel_size=(1,1), activation='relu')(base_model.output)\n",
    "#     x = Flatten()(x)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation='sigmoid', name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 30; batch_size = 64\n",
    "checkpoint = ModelCheckpoint('../working/xception_focal.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=9)\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "train_generator_warmup = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=False)\n",
    "validation_generator = data_generator.create_valid(\n",
    "    train_dataset_info[valid_indexes], batch_size, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "lrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=len(train_indexes),\n",
    "        epochs=1, batch_size=batch_size, verbose=0)\n",
    "# callbacks_list = [checkpoint, csv_logger, lrsched]\n",
    "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "1451/1451 [==============================] - 824s 568ms/step - loss: 5.3686 - f2: 0.0118\n",
      "Epoch 2/30\n",
      "1451/1451 [==============================] - 809s 557ms/step - loss: 4.2293 - f2: 0.0141\n",
      "Epoch 3/30\n",
      "1451/1451 [==============================] - 772s 532ms/step - loss: 4.1489 - f2: 0.0150\n",
      "Epoch 4/30\n",
      "1451/1451 [==============================] - 770s 531ms/step - loss: 4.2083 - f2: 0.0151\n",
      "Epoch 5/30\n",
      "1451/1451 [==============================] - 797s 550ms/step - loss: 4.1336 - f2: 0.0156\n",
      "Epoch 6/30\n",
      "1451/1451 [==============================] - 810s 559ms/step - loss: 4.1400 - f2: 0.0156\n",
      "Epoch 7/30\n",
      "1451/1451 [==============================] - 773s 533ms/step - loss: 4.0760 - f2: 0.0160\n",
      "Epoch 8/30\n",
      "1451/1451 [==============================] - 789s 543ms/step - loss: 4.1032 - f2: 0.0158\n",
      "Epoch 9/30\n",
      "1451/1451 [==============================] - 774s 534ms/step - loss: 4.0350 - f2: 0.0161\n",
      "Epoch 10/30\n",
      "1451/1451 [==============================] - 785s 541ms/step - loss: 4.0886 - f2: 0.0158\n",
      "Epoch 11/30\n",
      "1451/1451 [==============================] - 759s 523ms/step - loss: 4.0248 - f2: 0.0161\n",
      "Epoch 12/30\n",
      "1451/1451 [==============================] - 767s 529ms/step - loss: 4.0353 - f2: 0.0160\n",
      "Epoch 13/30\n",
      "1451/1451 [==============================] - 772s 532ms/step - loss: 3.9902 - f2: 0.0161\n",
      "Epoch 14/30\n",
      "1451/1451 [==============================] - 777s 536ms/step - loss: 4.0086 - f2: 0.0160\n",
      "Epoch 15/30\n",
      "1451/1451 [==============================] - 756s 521ms/step - loss: 3.9767 - f2: 0.0162\n",
      "Epoch 16/30\n",
      "1451/1451 [==============================] - 767s 529ms/step - loss: 3.9867 - f2: 0.0159\n",
      "Epoch 17/30\n",
      "1451/1451 [==============================] - 776s 535ms/step - loss: 3.9550 - f2: 0.0161\n",
      "Epoch 18/30\n",
      "1451/1451 [==============================] - 781s 538ms/step - loss: 3.9791 - f2: 0.0159\n",
      "Epoch 19/30\n",
      "1451/1451 [==============================] - 757s 522ms/step - loss: 3.9367 - f2: 0.0161\n",
      "Epoch 20/30\n",
      "1451/1451 [==============================] - 765s 527ms/step - loss: 3.9801 - f2: 0.0158\n",
      "Epoch 21/30\n",
      "1451/1451 [==============================] - 770s 530ms/step - loss: 3.9403 - f2: 0.0159\n",
      "Epoch 22/30\n",
      "1451/1451 [==============================] - 772s 532ms/step - loss: 3.9692 - f2: 0.0158\n",
      "Epoch 23/30\n",
      "1451/1451 [==============================] - 780s 537ms/step - loss: 3.9431 - f2: 0.0159\n",
      "Epoch 24/30\n",
      "1451/1451 [==============================] - 794s 547ms/step - loss: 3.9639 - f2: 0.0156\n",
      "Epoch 25/30\n",
      "1451/1451 [==============================] - 763s 526ms/step - loss: 3.9362 - f2: 0.0158\n",
      "Epoch 26/30\n",
      "1451/1451 [==============================] - 772s 532ms/step - loss: 3.9629 - f2: 0.0156\n",
      "Epoch 27/30\n",
      "1451/1451 [==============================] - 782s 539ms/step - loss: 3.9276 - f2: 0.0158\n",
      "Epoch 28/30\n",
      "1451/1451 [==============================] - 783s 540ms/step - loss: 3.9874 - f2: 0.0154\n",
      "Epoch 29/30\n",
      "1451/1451 [==============================] - 763s 526ms/step - loss: 3.9517 - f2: 0.0155\n",
      "Epoch 30/30\n",
      "1451/1451 [==============================] - 774s 534ms/step - loss: 3.9876 - f2: 0.0154\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=NUM_CLASSES)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-5,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(loss=focal_loss,\n",
    "            # loss='binary_crossentropy',\n",
    "              metrics=[f2],\n",
    "    optimizer=Adam(1e-3))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "hist1 = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=epochs,\n",
    "    max_queue_size=16, workers=WORKERS, use_multiprocessing=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train all layers\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# model.compile(loss=focal_loss,\n",
    "#             # loss='binary_crossentropy',\n",
    "#               metrics=[f2],\n",
    "#             optimizer=Adam(lr=1e-4))\n",
    "\n",
    "# hist = model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "#     epochs=epochs,\n",
    "#     verbose=1,\n",
    "#     max_queue_size=16, workers=WORKERS, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "# ax[0].set_title('loss')\n",
    "# ax[0].plot(hist1.epoch, hist1.history[\"loss\"], label=\"Train loss\")\n",
    "# # ax[0].plot(hist1.epoch, hist1.history[\"val_loss\"], label=\"Validation loss\")\n",
    "# ax[1].set_title('f2')\n",
    "# ax[1].plot(hist1.epoch, hist1.history[\"f2\"], label=\"Train F2\")\n",
    "# # ax[1].plot(hist1.epoch, hist1.history[\"val_f2\"], label=\"Validation F2\")\n",
    "# ax[0].legend()\n",
    "# ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__notebook_source__.ipynb', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../working/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('../input/imet-2019-fgvc6/sample_submission.csv')\n",
    "# model.load_weights('../working/xception_focal.h5')\n",
    "# predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [03:16<00:00,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16386, 1103) (16386, 1103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''Search for the best threshold regarding the validation set'''\n",
    "\n",
    "BATCH = 512\n",
    "fullValGen = data_generator.create_valid(\n",
    "    train_dataset_info[valid_indexes], BATCH, (SIZE,SIZE,3))\n",
    "\n",
    "n_val = round(train_dataset_info.shape[0]*0.15)//BATCH\n",
    "print(n_val)\n",
    "\n",
    "lastFullValPred = np.empty((0, NUM_CLASSES))\n",
    "lastFullValLabels = np.empty((0, NUM_CLASSES))\n",
    "for i in tqdm(range(n_val+1)): \n",
    "    im, lbl = next(fullValGen)\n",
    "    scores = model.predict(im)\n",
    "    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "print(lastFullValPred.shape, lastFullValLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f2(y_true, y_pred):\n",
    "    assert y_true.shape[0] == y_pred.shape[0]\n",
    "\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f2 = (1+beta_f2**2)*p*r / (p*beta_f2**2 + r + 1e-15)\n",
    "\n",
    "    return f2\n",
    "\n",
    "def find_best_fixed_threshold(preds, targs, do_plot=True):\n",
    "    score = []\n",
    "    thrs = np.arange(0, 0.5, 0.01)\n",
    "    for thr in tqdm(thrs):\n",
    "        score.append(my_f2(targs, (preds > thr).astype(int) ))\n",
    "    score = np.array(score)\n",
    "    pm = score.argmax()\n",
    "    best_thr, best_score = thrs[pm], score[pm].item()\n",
    "    print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n",
    "    if do_plot:\n",
    "        plt.plot(thrs, score)\n",
    "        plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n",
    "        plt.text(best_thr+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n",
    "        plt.show()\n",
    "    return best_thr, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:15<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr=0.260 F2=0.343\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_thr, best_score = find_best_fixed_threshold(lastFullValPred, lastFullValLabels, do_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-011dd5dc3b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/imet-2019-fgvc6/test/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscore_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(score_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'submit' is not defined"
     ]
    }
   ],
   "source": [
    "for i, name in tqdm(enumerate(submit['id'])):\n",
    "    path = os.path.join('../input/imet-2019-fgvc6/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))\n",
    "    score_predict = model.predict(image[np.newaxis]/255.)\n",
    "    # print(score_predict)\n",
    "    label_predict = np.arange(NUM_CLASSES)[score_predict[0]>=best_thr]\n",
    "    # print(label_predict)\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['attribute_ids'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
