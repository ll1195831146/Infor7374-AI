{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2-E1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ll1195831146/Infor7374-AI/blob/master/Assignment2/Assignment2_E1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K2DSRouT9Ary",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Experiment 1**"
      ]
    },
    {
      "metadata": {
        "id": "2NiEGR_fulXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "129cdad0-b768-42df-e660-ec57ccff484a"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "from keras import metrics\n",
        "import lasagne"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtQhbQAvu1rq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "77c2221a-6d74-437f-f58a-37ad114dcbb0"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IMLg2qe2u6gr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse -o nonempty drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3anNzBRMvKyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "9ce20579-90af-4e15-aad1-b10523a9ab7e"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(os.path.join(os.getcwd(),'drive'))\n",
        "print(os.getcwd())\n",
        "print(os.listdir(os.getcwd()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "['.Trash', 'Video_Games_Sales.csv', 'val_data', 'Getting started', 'Track-guidelines.pdf', 'AED_Lab1_Part1.mp4', 'AED_Lab1_Part2Final.mp4', 'games.zip', 'VideoGames-Version2 2.zip', 'VideoGames-Version4.zip', 'VideoGames-Version4-2.zip', 'NBA_stats_f (Recovered).ods', 'RL-NikBrown.odt', 'Resume0102.odt', '6210 Database Design.odt', 'Colab Notebooks', 'out_data_train', 'Imagenet32_train', 'out_data_val', 'x_train.npy', 'y_train.npy', 'x_train_1.npy', 'y_train_1.npy', 'x_val_1.npy', 'y_val_1.npy', 'out_data_train_1', 'out_data_val_1', 'Assignment2 - E 1.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OuJfFP2ovTO1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smy0jKnIvsjQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_databatch(data_folder, idx, img_size=32):\n",
        "    data_file = os.path.join(data_folder, 'train_data_batch_')\n",
        "\n",
        "    d = unpickle(data_file + str(idx))\n",
        "    x = d['data']\n",
        "    y = d['labels']\n",
        "    mean_image = d['mean']\n",
        "\n",
        "    x = x/np.float32(255)\n",
        "    mean_image = mean_image/np.float32(255)\n",
        "\n",
        "    # Labels are indexed from 1, shift it so that indexes start at 0\n",
        "    y = [i-1 for i in y]\n",
        "    data_size = x.shape[0]\n",
        "\n",
        "    x -= mean_image\n",
        "\n",
        "    img_size2 = img_size * img_size\n",
        "\n",
        "    x = np.dstack((x[:, :img_size2], x[:, img_size2:2*img_size2], x[:, 2*img_size2:]))\n",
        "    x = x.reshape((x.shape[0], img_size, img_size, 3))\n",
        "#     .transpose(0, 3, 1, 2)\n",
        "\n",
        "    # create mirrored images\n",
        "    X_train = x[0:data_size, :, :, :]\n",
        "    Y_train = y[0:data_size]\n",
        "    X_train_flip = X_train[:, :, :, ::-1]\n",
        "    Y_train_flip = Y_train\n",
        "    X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
        "    Y_train = np.concatenate((Y_train, Y_train_flip), axis=0)\n",
        "\n",
        "    return dict(\n",
        "        X_train=lasagne.utils.floatX(X_train),\n",
        "        Y_train=Y_train.astype('int32'),\n",
        "        mean=mean_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8lT5pKUvuNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_batch_1 = load_databatch('out_data_train_1', 1, img_size=32)\n",
        "train_data_batch_2 = load_databatch('out_data_train_1', 2, img_size=32)\n",
        "train_data_batch_3 = load_databatch('out_data_train_1', 3, img_size=32)\n",
        "train_data_batch_4 = load_databatch('out_data_train_1', 4, img_size=32)\n",
        "train_data_batch_5 = load_databatch('out_data_train_1', 5, img_size=32)\n",
        "train_data_batch_6 = load_databatch('out_data_train_1', 6, img_size=32)\n",
        "train_data_batch_7 = load_databatch('out_data_train_1', 7, img_size=32)\n",
        "train_data_batch_8 = load_databatch('out_data_train_1', 8, img_size=32)\n",
        "train_data_batch_9 = load_databatch('out_data_train_1', 9, img_size=32)\n",
        "train_data_batch_10 = load_databatch('out_data_train_1', 10, img_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ns9fG1BpzCZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data1 = train_data_batch_1['X_train']\n",
        "data2 = train_data_batch_2['X_train']\n",
        "data3 = train_data_batch_3['X_train']\n",
        "data4 = train_data_batch_4['X_train']\n",
        "data5 = train_data_batch_5['X_train']\n",
        "data6 = train_data_batch_6['X_train']\n",
        "data7 = train_data_batch_7['X_train']\n",
        "data8 = train_data_batch_8['X_train']\n",
        "data9 = train_data_batch_9['X_train']\n",
        "data10 = train_data_batch_10['X_train']\n",
        "\n",
        "label1 = train_data_batch_1['Y_train']\n",
        "label2 = train_data_batch_2['Y_train']\n",
        "label3 = train_data_batch_3['Y_train']\n",
        "label4 = train_data_batch_4['Y_train']\n",
        "label5 = train_data_batch_5['Y_train']\n",
        "label6 = train_data_batch_6['Y_train']\n",
        "label7 = train_data_batch_7['Y_train']\n",
        "label8 = train_data_batch_8['Y_train']\n",
        "label9 = train_data_batch_9['Y_train']\n",
        "label10 = train_data_batch_10['Y_train']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hqbMSVk7FbBO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.concatenate((data1,data2,data3,data4,data5,data6,data7,data8,data9,data10),axis=0)\n",
        "y_train = np.concatenate((label1,label2,label3,label4,label5,label6,label7,label8,label9,label10),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IOhoQWxv6IQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"x_train_1.npy\",x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ob8EOaos6vql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"y_train_1.npy\",y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GSa-i7zGFczi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_val_data(data, img_size=32):\n",
        "\n",
        "    d = unpickle(data)\n",
        "    x = d['data']\n",
        "    y = d['labels']\n",
        "\n",
        "    x = x/np.float32(255)\n",
        "\n",
        "    # Labels are indexed from 1, shift it so that indexes start at 0\n",
        "    y = [i-1 for i in y]\n",
        "    data_size = x.shape[0]\n",
        "\n",
        "    img_size2 = img_size * img_size\n",
        "\n",
        "    x = np.dstack((x[:, :img_size2], x[:, img_size2:2*img_size2], x[:, 2*img_size2:]))\n",
        "    x = x.reshape((x.shape[0], img_size, img_size, 3))\n",
        "#     .transpose(0, 3, 1, 2)\n",
        "\n",
        "    # create mirrored images\n",
        "    X_train = x[0:data_size, :, :, :]\n",
        "    Y_train = y[0:data_size]\n",
        "    X_train_flip = X_train[:, :, :, ::-1]\n",
        "    Y_train_flip = Y_train\n",
        "    X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
        "    Y_train = np.concatenate((Y_train, Y_train_flip), axis=0)\n",
        "\n",
        "    return dict(\n",
        "        X_val=lasagne.utils.floatX(X_train),\n",
        "        Y_val=Y_train.astype('int32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhW2eDdX68Sl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_data = load_val_data('out_data_val_1/val_data', img_size=32)\n",
        "x_val = val_data['X_val']\n",
        "y_val = val_data['Y_val']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hZeantS68b7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_Imagenet32_trained_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oa-vOwDr68fm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 196"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lettq7k768m1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08dmah3y68te",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.1,\n",
        "    # randomly shift images vertically (fraction of total height)\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.,  # set range for random shear\n",
        "    zoom_range=0.,  # set range for random zoom\n",
        "    channel_shift_range=0.,  # set range for random channel shifts\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,  # randomly flip images\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=None,\n",
        "    # set function that will be applied on each input\n",
        "    preprocessing_function=None,\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    data_format=None,\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "    validation_split=0.0)\n",
        "    \n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-4E59GRW7tmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        },
        "outputId": "86b73b17-65a8-44dd-edd3-a81132b62320"
      },
      "cell_type": "code",
      "source": [
        "model_best = Sequential()\n",
        "model_best.add(Conv2D(32, (3, 3), padding='same',\n",
        "input_shape=x_train.shape[1:]))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(Conv2D(32, (3, 3)))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_best.add(Dropout(0.1))\n",
        "\n",
        "model_best.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(Conv2D(64, (3, 3)))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_best.add(Dropout(0.1))\n",
        "\n",
        "model_best.add(Flatten())\n",
        "model_best.add(Dense(512))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(Dropout(0.1))\n",
        "model_best.add(Dense(num_classes))\n",
        "model_best.add(Activation('softmax'))\n",
        "\n",
        "model_best.compile(loss='categorical_crossentropy',\n",
        "optimizer=keras.optimizers.rmsprop(lr=0.0002, decay=1e-6),\n",
        "metrics=['accuracy',metrics.categorical_accuracy])\n",
        "\n",
        "model_best.fit_generator(datagen.flow(x_train, y_train,\n",
        "    batch_size=32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=1563,\n",
        "    validation_data=(x_val, y_val),\n",
        "    workers=4)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 5.0327 - acc: 0.0275 - categorical_accuracy: 0.0275 - val_loss: 6.6940 - val_acc: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 4.6464 - acc: 0.0653 - categorical_accuracy: 0.0653 - val_loss: 5.9914 - val_acc: 0.0069 - val_categorical_accuracy: 0.0069\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 54s 34ms/step - loss: 4.4378 - acc: 0.0905 - categorical_accuracy: 0.0905 - val_loss: 6.6915 - val_acc: 0.0046 - val_categorical_accuracy: 0.0046\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 4.2831 - acc: 0.1112 - categorical_accuracy: 0.1112 - val_loss: 6.5297 - val_acc: 0.0036 - val_categorical_accuracy: 0.0036\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 4.1702 - acc: 0.1244 - categorical_accuracy: 0.1244 - val_loss: 6.7137 - val_acc: 0.0033 - val_categorical_accuracy: 0.0033\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 4.0463 - acc: 0.1421 - categorical_accuracy: 0.1421 - val_loss: 6.8409 - val_acc: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 3.9684 - acc: 0.1515 - categorical_accuracy: 0.1515 - val_loss: 6.9160 - val_acc: 0.0041 - val_categorical_accuracy: 0.0041\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 3.9038 - acc: 0.1605 - categorical_accuracy: 0.1605 - val_loss: 7.0997 - val_acc: 0.0071 - val_categorical_accuracy: 0.0071\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 3.8280 - acc: 0.1745 - categorical_accuracy: 0.1745 - val_loss: 7.2778 - val_acc: 0.0048 - val_categorical_accuracy: 0.0048\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 3.7701 - acc: 0.1812 - categorical_accuracy: 0.1812 - val_loss: 7.1582 - val_acc: 0.0048 - val_categorical_accuracy: 0.0048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05ca197b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "0OsaqdQu7tut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7560a3d8-bd3c-483d-b423-325fe866e6ee"
      },
      "cell_type": "code",
      "source": [
        "score = model_best.evaluate(x_val, y_val, verbose=1)\n",
        "print('Val loss:', score[0])\n",
        "print('Val accuracy:', score[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3918/3918 [==============================] - 1s 167us/step\n",
            "Val loss: 7.158221487246831\n",
            "Val accuracy: 0.004849412965798877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5pV8uYpW957g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Experiments**"
      ]
    },
    {
      "metadata": {
        "id": "t4rC6TzyLvb9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_train.shape\n",
        "# np.save(\"x_train.npy\",x_train)\n",
        "x_train = np.load(\"x_train.npy\")\n",
        "x_train = x_train.transpose(0,2,3,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJrHnz8kakC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np.load(\"y_train.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lniiXC-SFebd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_data = load_val_data('out_data_val/val_data', img_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZWXmhKJFFjlk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = val_data['X_val']\n",
        "y_val = val_data['Y_val']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2eqd6-SIFn4Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_Imagenet32_trained_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "74JiqG6WFpPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihX_mQy4FqhM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKrMerz1Fu4B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.1,\n",
        "    # randomly shift images vertically (fraction of total height)\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.,  # set range for random shear\n",
        "    zoom_range=0.,  # set range for random zoom\n",
        "    channel_shift_range=0.,  # set range for random channel shifts\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,  # randomly flip images\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=None,\n",
        "    # set function that will be applied on each input\n",
        "    preprocessing_function=None,\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    data_format=None,\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "    validation_split=0.0)\n",
        "    \n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfarxHbOF_r4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        },
        "outputId": "aeeee421-2ce4-476e-b216-008628cf9849"
      },
      "cell_type": "code",
      "source": [
        "model_best = Sequential()\n",
        "model_best.add(Conv2D(32, (3, 3), padding='same',\n",
        "input_shape=x_train.shape[1:]))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(Conv2D(32, (3, 3)))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_best.add(Dropout(0.1))\n",
        "\n",
        "model_best.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(Conv2D(64, (3, 3)))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_best.add(Dropout(0.1))\n",
        "\n",
        "model_best.add(Flatten())\n",
        "model_best.add(Dense(512))\n",
        "model_best.add(Activation('relu'))\n",
        "model_best.add(Dropout(0.1))\n",
        "model_best.add(Dense(num_classes))\n",
        "model_best.add(Activation('softmax'))\n",
        "\n",
        "model_best.compile(loss='categorical_crossentropy',\n",
        "optimizer=keras.optimizers.rmsprop(lr=0.0002, decay=1e-6),\n",
        "metrics=['accuracy',metrics.categorical_accuracy])\n",
        "\n",
        "model_best.fit_generator(datagen.flow(x_train, y_train,\n",
        "    batch_size=32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=1563,\n",
        "    validation_data=(x_val, y_val),\n",
        "    workers=4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 5.0350 - acc: 0.0288 - categorical_accuracy: 0.0288 - val_loss: 6.4525 - val_acc: 0.0056 - val_categorical_accuracy: 0.0056\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 4.5877 - acc: 0.0711 - categorical_accuracy: 0.0711 - val_loss: 6.7511 - val_acc: 0.0063 - val_categorical_accuracy: 0.0063\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 4.3488 - acc: 0.1008 - categorical_accuracy: 0.1008 - val_loss: 6.4371 - val_acc: 0.0035 - val_categorical_accuracy: 0.0035\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 4.1712 - acc: 0.1239 - categorical_accuracy: 0.1239 - val_loss: 6.7610 - val_acc: 0.0030 - val_categorical_accuracy: 0.0030\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 4.0457 - acc: 0.1392 - categorical_accuracy: 0.1392 - val_loss: 6.9797 - val_acc: 0.0033 - val_categorical_accuracy: 0.0033\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 3.9240 - acc: 0.1571 - categorical_accuracy: 0.1571 - val_loss: 6.9263 - val_acc: 0.0038 - val_categorical_accuracy: 0.0038\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 3.8466 - acc: 0.1742 - categorical_accuracy: 0.1742 - val_loss: 7.2830 - val_acc: 0.0046 - val_categorical_accuracy: 0.0046\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 3.7827 - acc: 0.1807 - categorical_accuracy: 0.1807 - val_loss: 7.1672 - val_acc: 0.0051 - val_categorical_accuracy: 0.0051\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 3.7019 - acc: 0.1917 - categorical_accuracy: 0.1917 - val_loss: 7.3309 - val_acc: 0.0061 - val_categorical_accuracy: 0.0061\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 3.6592 - acc: 0.2022 - categorical_accuracy: 0.2022 - val_loss: 7.4407 - val_acc: 0.0056 - val_categorical_accuracy: 0.0056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff212e547b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "w4bTbnPlGPFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1f356584-ea1b-452f-eb25-22cb754ecdac"
      },
      "cell_type": "code",
      "source": [
        "score = model_best.evaluate(x_val, y_val, verbose=1)\n",
        "print('Val loss:', score[0])\n",
        "print('Val accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3952/3952 [==============================] - 1s 181us/step\n",
            "Val loss: 7.440697245269652\n",
            "Val accuracy: 0.005566801619433198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GZITmJjOvXIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}