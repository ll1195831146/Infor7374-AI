{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E5&6-Transfer Learning and Fine Tuning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ll1195831146/Infor7374-AI/blob/master/Assignment2/E5%266_Transfer_Learning_and_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M1l0bzD1g8kp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Convolution2D, \\\n",
        "    GlobalAveragePooling2D, Dense, BatchNormalization, Activation\n",
        "from keras.models import Model\n",
        "from keras.metrics import top_k_categorical_accuracy, categorical_accuracy\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.layers import DepthwiseConv2D\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10 \n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXcSWut_1woi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#base setup\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "data_augmentation = True\n",
        "subtract_pixel_mean = True\n",
        "num_predictions = 20\n",
        "size = 224\n",
        "alpha = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uIZpCV9jE2dz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resize_image_arr(img_arr):\n",
        "    x_resized_list = []\n",
        "    for i in range(img_arr.shape[0]):\n",
        "        img = img_arr[0]\n",
        "        resized_img = resize(img, (size, size))\n",
        "        x_resized_list.append(resized_img)\n",
        "    return np.stack(x_resized_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyJnf2BAhBDS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train[0:2000]\n",
        "y_train = y_train[0:2000]\n",
        "x_test = x_test[0:500]\n",
        "y_test = y_test[0:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kSL1A5vcFp_0",
        "colab_type": "code",
        "outputId": "b343cdd5-aa99-4f95-bac0-81f22db8c811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# Resize image arrays\n",
        "x_train = resize_image_arr(x_train)\n",
        "x_test = resize_image_arr(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "khEoi_f2CxMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lEqp9NvjBSVy",
        "colab_type": "code",
        "outputId": "23bab4f3-0c79-401e-f521-d0b044ff9be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (2000, 224, 224, 3)\n",
            "2000 train samples\n",
            "500 test samples\n",
            "y_train shape: (2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v_H0TZIj2evC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJrIuWld3Awc",
        "colab_type": "code",
        "outputId": "59d18809-6af9-4740-c765-ce6c04761292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3094
        }
      },
      "cell_type": "code",
      "source": [
        "model = MobileNet(input_shape=input_shape, weights='imagenet', include_top=False, alpha=alpha)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "=================================================================\n",
            "Total params: 3,228,864\n",
            "Trainable params: 3,206,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qXD03VxCh4wa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate_on_imagenet\n",
        "\n",
        "# eval_data = model.evaluate_generator(datagen.flow_from_directory(\n",
        "#            '/root/imagenet/validation',\n",
        "#            target_size=(edge_size, edge_size),\n",
        "#            batch_size=BATCH_SIZE,\n",
        "#            class_mode='categorical'),steps=100)\n",
        "#     for i, metric_name in enumerate(base_model.metrics_names):\n",
        "#        print \"   - {0}: {1}\".format(metric_name, eval_data[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4t4nIu4B8Vt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# and a logistic layer -- 10 classes for CIFAR10\n",
        "predictions = Dense(num_classes, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CO3lmEhB8N1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=model.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ze5fDIX2hTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUTbJjyC2lw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9qbM03r1IEb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxzoH4gX_RQ7",
        "colab_type": "code",
        "outputId": "a0668791-ed66-42d9-c24e-3d8b8c8e1a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "62/62 [==============================] - 32s 515ms/step - loss: 2.4317 - categorical_accuracy: 0.0998 - top_k_categorical_accuracy: 0.4980 - val_loss: 2.4439 - val_categorical_accuracy: 0.1140 - val_top_k_categorical_accuracy: 0.5020\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 23s 367ms/step - loss: 2.4198 - categorical_accuracy: 0.0932 - top_k_categorical_accuracy: 0.4929 - val_loss: 2.3373 - val_categorical_accuracy: 0.1140 - val_top_k_categorical_accuracy: 0.5160\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 23s 364ms/step - loss: 2.4004 - categorical_accuracy: 0.0948 - top_k_categorical_accuracy: 0.5116 - val_loss: 2.3914 - val_categorical_accuracy: 0.0800 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 23s 365ms/step - loss: 2.3859 - categorical_accuracy: 0.1048 - top_k_categorical_accuracy: 0.5156 - val_loss: 2.4244 - val_categorical_accuracy: 0.1140 - val_top_k_categorical_accuracy: 0.4820\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 23s 364ms/step - loss: 2.3802 - categorical_accuracy: 0.1018 - top_k_categorical_accuracy: 0.5131 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ic2PqH6xI6Xh",
        "colab_type": "code",
        "outputId": "124dc3fb-f73c-4653-a98d-f5eb4b9cb47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 2s 4ms/step\n",
            "Test loss: 2.496279285430908\n",
            "Test accuracy: 0.098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PDGweB_z6DWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning**\n",
        "*   New dataset is small and similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n",
        "*   New dataset is large and similar to the original dataset. Since we have more data, we can have more confidence that we won’t overfit if we were to try to fine-tune through the full network.\n",
        "*   New dataset is small but very different from the original dataset. Since the data is small, it is likely best to only train a linear classifier. Since the dataset is very different, it might not be best to train the classifier form the top of the network, which contains more dataset-specific features. Instead, it might work better to train the SVM classifier from activations somewhere earlier in the network.\n",
        "*   New dataset is large and very different from the original dataset. Since the dataset is very large, we may expect that we can afford to train a ConvNet from scratch. However, in practice it is very often still beneficial to initialize with weights from a pretrained model. In this case, we would have enough data and confidence to fine-tune through the entire network.\n"
      ]
    },
    {
      "metadata": {
        "id": "4HsFlW0k0tD1",
        "colab_type": "code",
        "outputId": "9844a219-3271-4fcd-b678-5b328373cb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        }
      },
      "cell_type": "code",
      "source": [
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_4\n",
            "1 conv1_pad\n",
            "2 conv1\n",
            "3 conv1_bn\n",
            "4 conv1_relu\n",
            "5 conv_dw_1\n",
            "6 conv_dw_1_bn\n",
            "7 conv_dw_1_relu\n",
            "8 conv_pw_1\n",
            "9 conv_pw_1_bn\n",
            "10 conv_pw_1_relu\n",
            "11 conv_pad_2\n",
            "12 conv_dw_2\n",
            "13 conv_dw_2_bn\n",
            "14 conv_dw_2_relu\n",
            "15 conv_pw_2\n",
            "16 conv_pw_2_bn\n",
            "17 conv_pw_2_relu\n",
            "18 conv_dw_3\n",
            "19 conv_dw_3_bn\n",
            "20 conv_dw_3_relu\n",
            "21 conv_pw_3\n",
            "22 conv_pw_3_bn\n",
            "23 conv_pw_3_relu\n",
            "24 conv_pad_4\n",
            "25 conv_dw_4\n",
            "26 conv_dw_4_bn\n",
            "27 conv_dw_4_relu\n",
            "28 conv_pw_4\n",
            "29 conv_pw_4_bn\n",
            "30 conv_pw_4_relu\n",
            "31 conv_dw_5\n",
            "32 conv_dw_5_bn\n",
            "33 conv_dw_5_relu\n",
            "34 conv_pw_5\n",
            "35 conv_pw_5_bn\n",
            "36 conv_pw_5_relu\n",
            "37 conv_pad_6\n",
            "38 conv_dw_6\n",
            "39 conv_dw_6_bn\n",
            "40 conv_dw_6_relu\n",
            "41 conv_pw_6\n",
            "42 conv_pw_6_bn\n",
            "43 conv_pw_6_relu\n",
            "44 conv_dw_7\n",
            "45 conv_dw_7_bn\n",
            "46 conv_dw_7_relu\n",
            "47 conv_pw_7\n",
            "48 conv_pw_7_bn\n",
            "49 conv_pw_7_relu\n",
            "50 conv_dw_8\n",
            "51 conv_dw_8_bn\n",
            "52 conv_dw_8_relu\n",
            "53 conv_pw_8\n",
            "54 conv_pw_8_bn\n",
            "55 conv_pw_8_relu\n",
            "56 conv_dw_9\n",
            "57 conv_dw_9_bn\n",
            "58 conv_dw_9_relu\n",
            "59 conv_pw_9\n",
            "60 conv_pw_9_bn\n",
            "61 conv_pw_9_relu\n",
            "62 conv_dw_10\n",
            "63 conv_dw_10_bn\n",
            "64 conv_dw_10_relu\n",
            "65 conv_pw_10\n",
            "66 conv_pw_10_bn\n",
            "67 conv_pw_10_relu\n",
            "68 conv_dw_11\n",
            "69 conv_dw_11_bn\n",
            "70 conv_dw_11_relu\n",
            "71 conv_pw_11\n",
            "72 conv_pw_11_bn\n",
            "73 conv_pw_11_relu\n",
            "74 conv_pad_12\n",
            "75 conv_dw_12\n",
            "76 conv_dw_12_bn\n",
            "77 conv_dw_12_relu\n",
            "78 conv_pw_12\n",
            "79 conv_pw_12_bn\n",
            "80 conv_pw_12_relu\n",
            "81 conv_dw_13\n",
            "82 conv_dw_13_bn\n",
            "83 conv_dw_13_relu\n",
            "84 conv_pw_13\n",
            "85 conv_pw_13_bn\n",
            "86 conv_pw_13_relu\n",
            "87 global_average_pooling2d_4\n",
            "88 dense_7\n",
            "89 dense_8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vZC2M-SG0ukp",
        "colab_type": "code",
        "outputId": "605cbebf-878d-4323-e74e-3248c0e0cbcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "# We will finetune from add_9\n",
        "for layer in model.layers[:99]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[99:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "# Train!\n",
        "train_model = model.fit_generator(\n",
        "    datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "62/62 [==============================] - 26s 413ms/step - loss: 2.3591 - categorical_accuracy: 0.1013 - top_k_categorical_accuracy: 0.5086 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 18s 287ms/step - loss: 2.3619 - categorical_accuracy: 0.1018 - top_k_categorical_accuracy: 0.5070 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 19s 310ms/step - loss: 2.3580 - categorical_accuracy: 0.1028 - top_k_categorical_accuracy: 0.5131 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 19s 310ms/step - loss: 2.3627 - categorical_accuracy: 0.0988 - top_k_categorical_accuracy: 0.5051 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 19s 304ms/step - loss: 2.3596 - categorical_accuracy: 0.1028 - top_k_categorical_accuracy: 0.5086 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-yZZXojJ0xt8",
        "colab_type": "code",
        "outputId": "0c0b758c-47d9-4428-c26f-6634a5a6a943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 2s 3ms/step\n",
            "Test loss: 2.496279285430908\n",
            "Test accuracy: 0.5120000002384186\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}