{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['resnet50', 'keras-pretrain-model-weights', 'imet-2019-fgvc6']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image, ImageOps, ImageFilter\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score\nfrom keras.utils import Sequence\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSIZE = 200\nNUM_CLASSES = 1103\nbeta_f2=2\ngamma = 1.0","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataset info\npath_to_train = '../input/imet-2019-fgvc6/train/'\ndata = pd.read_csv('../input/imet-2019-fgvc6/train.csv')\n\ntrain_dataset_info = []\nfor name, labels in zip(data['id'], data['attribute_ids'].str.split(' ')):\n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss\n\ndef f2(y_true, y_pred):\n    #y_pred = K.round(y_pred)\n#     y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), F2_THRESHOLD), K.floatx())\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f2 = (1+beta_f2**2)*p*r / (p*beta_f2**2 + r + K.epsilon())\n    f2 = tf.where(tf.is_nan(f2), tf.zeros_like(f2), f2)\n    return K.mean(f2)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resize_weird_images(img, SIZE):\n    aspect_ratio = img.size[0] / img.size[1]\n    if aspect_ratio < 0.5:\n        w_resized = int(img.size[0] * SIZE / img.size[1])\n        resized = img.resize((w_resized ,SIZE))\n        pad_width = SIZE - w_resized\n        padding = (pad_width // 2, 0, pad_width-(pad_width//2), 0)\n        img = ImageOps.expand(resized, padding, fill=\"white\")\n    elif aspect_ratio > 2:\n        h_resized = int(img.size[1] * SIZE / img.size[0])\n        resized = img.resize((SIZE, h_resized))\n        pad_height = SIZE - h_resized\n        padding = (0, pad_height // 2, 0, pad_height-(pad_height//2))\n        img = ImageOps.expand(resized, padding, fill=\"white\")\n    \n    return img","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n\nclass data_generator(Sequence):\n    \n    def create_train(dataset_info, batch_size, shape, augument=True):\n        assert shape[2] == 3\n        while True:\n            dataset_info = shuffle(dataset_info)\n            for start in range(0, len(dataset_info), batch_size):\n                end = min(start + batch_size, len(dataset_info))\n                batch_images = []\n                X_train_batch = dataset_info[start:end]\n                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n                for i in range(len(X_train_batch)):\n                    image = data_generator.load_image(\n                        X_train_batch[i]['path'], shape)   \n                    if augument:\n                        image = data_generator.augment(image)\n                    batch_images.append(image/255.)\n                    batch_labels[i][X_train_batch[i]['labels']] = 1\n                    \n                yield np.array(batch_images, np.float32), batch_labels\n\n    def create_valid(dataset_info, batch_size, shape, augument=False):\n        assert shape[2] == 3\n        while True:\n            # dataset_info = shuffle(dataset_info)\n            for start in range(0, len(dataset_info), batch_size):\n                end = min(start + batch_size, len(dataset_info))\n                batch_images = []\n                X_train_batch = dataset_info[start:end]\n                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n                for i in range(len(X_train_batch)):\n                    image = data_generator.load_image(\n                        X_train_batch[i]['path'], shape)   \n                    if augument:\n                        image = data_generator.augment(image)\n                    batch_images.append(image/255.)\n                    batch_labels[i][X_train_batch[i]['labels']] = 1\n                yield np.array(batch_images, np.float32), batch_labels\n\n\n    def load_image(path, shape):\n        image = PIL.Image.open(path+'.png')\n        image = resize_weird_images(image, SIZE)\n        image = np.array(image)\n        image = cv2.resize(image, (SIZE, SIZE))\n        return image\n\n    def augment(image):\n        augment_img = iaa.Sequential([\n            sometimes(\n            iaa.OneOf([\n                # iaa.AddToHueAndSaturation((-20, 20)),\n                iaa.Add((-10, 10), per_channel=0.5),\n                iaa.Multiply((0.9, 1.1), per_channel=0.5),\n                # iaa.GaussianBlur((0, 0.5)), # blur images with a sigma between 0 and 3.0\n                iaa.ContrastNormalization((0.8, 1.2), per_channel=0.5), # improve or worsen the contrast\n                iaa.Sharpen(alpha=(0, 0.2), lightness=(0.8, 1.2)), # sharpen images\n                iaa.Emboss(alpha=(0, 0.5), strength=(0, 0.5)), # emboss images\n                # iaa.Crop(percent=(0, 0.1))\n                ])\n            ),\n            iaa.OneOf([\n#                 iaa.Affine(rotate=0),\n#                 iaa.Affine(rotate=90),\n#                 iaa.Affine(rotate=180),\n#                 iaa.Affine(rotate=270),\n                iaa.Fliplr(0.5),\n                # iaa.Flipud(0.5),\n            ])], random_order=True)\n\n        image_aug = augment_img.augment_image(image)\n        return image_aug","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import (Activation, Dropout, Multiply, Flatten, Dense, Add, MaxPooling2D, GlobalMaxPooling2D, AveragePooling2D, GlobalAveragePooling2D,\n                          BatchNormalization, Input, Conv2D, Lambda, Concatenate)\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport keras\nfrom keras.models import Model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom keras_applications.imagenet_utils import _obtain_input_shape","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 1e-4\nLR_FACTOR = 0.45\nLR_WARM = 1e-3\nLR_MAX=1e-3\nN_DATA_POINT=8000\nEPOCHS=10\nBATCH_SIZE=48","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_applications import imagenet_utils as utils\n\ndef ResNet(stack_fn,\n           preact,\n           use_bias,\n           model_name='resnet',\n           include_top=True,\n           weights='imagenet',\n           input_tensor=None,\n           input_shape=None,\n           pooling=None,\n           classes=1000,\n           **kwargs):\n    \"\"\"Instantiates the ResNet, ResNetV2, and ResNeXt architecture.\n    Optionally loads weights pre-trained on ImageNet.\n    Note that the data format convention used by the model is\n    the one specified in your Keras config at `~/.keras/keras.json`.\n    # Arguments\n        stack_fn: a function that returns output tensor for the\n            stacked residual blocks.\n        preact: whether to use pre-activation or not\n            (True for ResNetV2, False for ResNet and ResNeXt).\n        use_bias: whether to use biases for convolutional layers or not\n            (True for ResNet and ResNetV2, False for ResNeXt).\n        model_name: string, model name.\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor\n            (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels.\n        pooling: optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    global backend, layers, models, keras_utils\n    # backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n    backend, layers, models, keras_utils = keras.backend, keras.layers, keras.models, keras.utils\n\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = utils._obtain_input_shape(input_shape,\n                                          default_size=224,\n                                          min_size=32,\n                                          data_format=backend.image_data_format(),\n                                          require_flatten=include_top,\n                                          weights=weights)\n\n    if input_tensor is None:\n        img_input = layers.Input(shape=input_shape)\n    else:\n        if not backend.is_keras_tensor(input_tensor):\n            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n\n    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n    x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n\n    if preact is False:\n        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                      name='conv1_bn')(x)\n        x = layers.Activation('relu', name='conv1_relu')(x)\n\n    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n\n    x = stack_fn(x)\n\n    if preact is True:\n        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                      name='post_bn')(x)\n        x = layers.Activation('relu', name='post_relu')(x)\n\n    if include_top:\n        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n        x = layers.Dense(classes, activation='softmax', name='probs')(x)\n    else:\n        if pooling == 'avg':\n            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n        elif pooling == 'max':\n            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = keras_utils.get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model.\n    model = models.Model(inputs, x, name=model_name)\n\n    # Load weights.\n    if (weights == 'imagenet') and (model_name in WEIGHTS_HASHES):\n        if include_top:\n            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels.h5'\n            file_hash = WEIGHTS_HASHES[model_name][0]\n        else:\n            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_notop.h5'\n            file_hash = WEIGHTS_HASHES[model_name][1]\n        weights_path = keras_utils.get_file(file_name,\n                                            BASE_WEIGHTS_PATH + file_name,\n                                            cache_subdir='models',\n                                            file_hash=file_hash)\n        model.load_weights(weights_path)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\ndef block2(x, filters, kernel_size=3, stride=1,\n           conv_shortcut=False, name=None):\n    \"\"\"A residual block.\n    # Arguments\n        x: input tensor.\n        filters: integer, filters of the bottleneck layer.\n        kernel_size: default 3, kernel size of the bottleneck layer.\n        stride: default 1, stride of the first layer.\n        conv_shortcut: default False, use convolution shortcut if True,\n            otherwise identity shortcut.\n        name: string, block label.\n    # Returns\n        Output tensor for the residual block.\n    \"\"\"\n    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n\n    preact = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                       name=name + '_preact_bn')(x)\n    preact = layers.Activation('relu', name=name + '_preact_relu')(preact)\n\n    if conv_shortcut is True:\n        shortcut = layers.Conv2D(4 * filters, 1, strides=stride,\n                                 name=name + '_0_conv')(preact)\n    else:\n        shortcut = layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\n\n    x = layers.Conv2D(filters, 1, strides=1, use_bias=False,\n                      name=name + '_1_conv')(preact)\n    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                  name=name + '_1_bn')(x)\n    x = layers.Activation('relu', name=name + '_1_relu')(x)\n\n    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\n    x = layers.Conv2D(filters, kernel_size, strides=stride,\n                      use_bias=False, name=name + '_2_conv')(x)\n    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                  name=name + '_2_bn')(x)\n    x = layers.Activation('relu', name=name + '_2_relu')(x)\n\n    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n    x = layers.Add(name=name + '_out')([shortcut, x])\n    return x\n\n\ndef stack2(x, filters, blocks, stride1=2, name=None):\n    \"\"\"A set of stacked residual blocks.\n    # Arguments\n        x: input tensor.\n        filters: integer, filters of the bottleneck layer in a block.\n        blocks: integer, blocks in the stacked blocks.\n        stride1: default 2, stride of the first layer in the first block.\n        name: string, stack label.\n    # Returns\n        Output tensor for the stacked blocks.\n    \"\"\"\n    x = block2(x, filters, conv_shortcut=True, name=name + '_block1')\n    for i in range(2, blocks):\n        x = block2(x, filters, name=name + '_block' + str(i))\n    x = block2(x, filters, stride=stride1, name=name + '_block' + str(blocks))\n    return x\n\ndef ResNet50V2(include_top=True,\n               weights='imagenet',\n               input_tensor=None,\n               input_shape=None,\n               pooling=None,\n               classes=1000,\n               **kwargs):\n    def stack_fn(x):\n        x = stack2(x, 64, 3, name='conv2')\n        x = stack2(x, 128, 4, name='conv3')\n        x = stack2(x, 256, 6, name='conv4')\n        x = stack2(x, 512, 3, stride1=1, name='conv5')\n        return x\n    return ResNet(stack_fn, True, True, 'resnet50v2',\n                  include_top, weights,\n                  input_tensor, input_shape,\n                  pooling, classes,\n                  **kwargs)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback\n\ndef get_1cycle_schedule(lr_max=LR_MAX, n_data_points=N_DATA_POINT, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0):          \n    if verbose > 0:\n        print(\"Setting up 1Cycle LR schedule...\")\n    pct_start, div_factor = 0.3, 25.        # @sgugger's parameters in fastai code\n    lr_start = lr_max/div_factor\n    lr_end = lr_start/1e4\n    n_iter = (n_data_points * epochs // batch_size) + 1    # number of iterations\n    a1 = int(n_iter * pct_start)\n    a2 = n_iter - a1\n\n    # make look-up table\n    lrs_first = np.linspace(lr_start, lr_max, a1)            # linear growth\n    lrs_second = (lr_max-lr_end)*(1+np.cos(np.linspace(0,np.pi,a2)))/2 + lr_end  # cosine annealing\n    lrs = np.concatenate((lrs_first, lrs_second))\n    return lrs\n\nclass OneCycleScheduler(Callback):\n    def __init__(self, **kwargs):\n        super(OneCycleScheduler, self).__init__()\n        self.verbose = kwargs.get('verbose', 0)\n        self.lrs = get_1cycle_schedule(**kwargs)\n        self.iteration = 0\n\n    def on_batch_begin(self, batch, logs=None):\n        lr = self.lrs[self.iteration]\n        K.set_value(self.model.optimizer.lr, lr)         # here's where the assignment takes place\n        if self.verbose > 0:\n            print('\\nIteration %06d: OneCycleScheduler setting learning '\n                  'rate to %s.' % (self.iteration, lr))\n        self.iteration += 1\n\n    def on_epoch_end(self, epoch, logs=None):  # this is unchanged from Keras LearningRateScheduler\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n        self.iteration = 0","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create callbacks list\nfrom keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n                             \nfrom sklearn.model_selection import train_test_split\n\nepochs = EPOCHS\nbatch_size = BATCH_SIZE\n\ncheckpoint = ModelCheckpoint('../working/Resnet50_focal.h5', monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n                                   verbose=1, mode='auto', epsilon=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=9)\n\ncsv_logger = CSVLogger(filename='../working/training_log.csv',\n                       separator=',',\n                       append=True)\n\n\n# split data into train, valid\nindexes = np.arange(train_dataset_info.shape[0])\ntrain_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n\n# create train and valid datagens\ntrain_generator = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\ntrain_generator_warmup = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=False)\nvalidation_generator = data_generator.create_valid(\n    train_dataset_info[valid_indexes], batch_size, (SIZE,SIZE,3), augument=False)\n\n\nlrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=len(train_indexes),\n        epochs=1, batch_size=batch_size, verbose=0)\n# callbacks_list = [checkpoint, csv_logger, lrsched]\ncallbacks_list = [checkpoint, csv_logger, reduceLROnPlat]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LRFinder(Callback):\n    \n    '''\n    A simple callback for finding the optimal learning rate range for your model + dataset. \n    \n    # Usage\n        ```python\n            lr_finder = LRFinder(min_lr=1e-5, \n                                 max_lr=1e-2, \n                                 steps_per_epoch=np.ceil(epoch_size/batch_size), \n                                 epochs=3)\n            model.fit(X_train, Y_train, callbacks=[lr_finder])\n            \n            lr_finder.plot_loss()\n        ```\n    \n    # Arguments\n        min_lr: The lower bound of the learning rate range for the experiment.\n        max_lr: The upper bound of the learning rate range for the experiment.\n        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n        epochs: Number of epochs to run experiment. Usually between 2 and 4 epochs is sufficient. \n        \n    # References\n        Blog post: jeremyjordan.me/nn-learning-rate\n        Original paper: https://arxiv.org/abs/1506.01186\n    '''\n    \n    def __init__(self, min_lr=1e-5, max_lr=1e-2, steps_per_epoch=None, epochs=None):\n        super().__init__()\n        \n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.total_iterations = steps_per_epoch * epochs\n        self.iteration = 0\n        self.history = {}\n        \n    def clr(self):\n        '''Calculate the learning rate.'''\n        x = self.iteration / self.total_iterations \n        return self.min_lr + (self.max_lr-self.min_lr) * x\n        \n    def on_train_begin(self, logs=None):\n        '''Initialize the learning rate to the minimum value at the start of training.'''\n        logs = logs or {}\n        K.set_value(self.model.optimizer.lr, self.min_lr)\n        \n    def on_batch_end(self, epoch, logs=None):\n        '''Record previous batch statistics and update the learning rate.'''\n        logs = logs or {}\n        self.iteration += 1\n\n        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n        self.history.setdefault('iterations', []).append(self.iteration)\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n            \n        K.set_value(self.model.optimizer.lr, self.clr())\n \n    def plot_lr(self):\n        '''Helper function to quickly inspect the learning rate schedule.'''\n        plt.plot(self.history['iterations'], self.history['lr'])\n        plt.yscale('log')\n        plt.xlabel('Iteration')\n        plt.ylabel('Learning rate')\n        plt.show()\n   \n    def plot_loss(self):\n        '''Helper function to quickly observe the learning rate experiment results.'''\n        plt.plot(self.history['lr'], self.history['loss'])\n        plt.xscale('log')\n        plt.xlabel('Learning rate')\n        plt.ylabel('Loss')\n        plt.show()","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\nfrom keras.initializers import glorot_uniform\n\ndef res_conv(X, filters, base, s):\n    \n    name_base = base + '/branch'\n    \n    F1, F2, F3 = filters\n\n    ##### Branch1 is the main path and Branch2 is the shortcut path #####\n    \n    X_shortcut = X\n    \n    ##### Branch1 #####\n    # First component of Branch1 \n    X = BatchNormalization(axis=-1, name=name_base + '1/bn_1')(X)\n    X= Activation('relu', name=name_base + '1/relu_1')(X)\n    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)\n\n    # Second component of Branch1\n    X = BatchNormalization(axis=-1, name=name_base + '1/bn_2')(X)\n    X = Activation('relu', name=name_base + '1/relu_2')(X)\n    X = Conv2D(filters=F2, kernel_size=(3,3), strides=(s,s), padding='same', name=name_base + '1/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)\n    \n    # Third component of Branch1\n    X = BatchNormalization(axis=-1, name=name_base + '1/bn_3')(X)\n    X = Activation('relu', name=name_base + '1/relu_3')(X)\n    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_3', kernel_initializer=glorot_uniform(seed=0))(X)\n    \n    ##### Branch2 ####\n    X_shortcut = BatchNormalization(axis=-1, name=name_base + '2/bn_1')(X_shortcut)\n    X_shortcut= Activation('relu', name=name_base + '2/relu_1')(X_shortcut)\n    X_shortcut = Conv2D(filters=F3, kernel_size=(1,1), strides=(s,s), padding='valid', name=name_base + '2/conv_1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    \n    # Final step: Add Branch1 and Branch2\n    X = Add(name=base + '/Add')([X, X_shortcut])\n\n    return X\n\ndef res_identity(X, filters, base):\n    \n    name_base = base + '/branch'\n    \n    F1, F2, F3 = filters\n\n    ##### Branch1 is the main path and Branch2 is the shortcut path #####\n    \n    X_shortcut = X\n    \n    ##### Branch1 #####\n    # First component of Branch1 \n    X = BatchNormalization(axis=-1, name=name_base + '1/bn_1')(X)\n    Shortcut= Activation('relu', name=name_base + '1/relu_1')(X)\n    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_1', kernel_initializer=glorot_uniform(seed=0))(Shortcut)\n\n    # Second component of Branch1\n    X = BatchNormalization(axis=-1, name=name_base + '1/bn_2')(X)\n    X = Activation('relu', name=name_base + '1/relu_2')(X)\n    X = Conv2D(filters=F2, kernel_size=(3,3), strides=(1,1), padding='same', name=name_base + '1/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)\n    \n    # Third component of Branch1\n    X = BatchNormalization(axis=-1, name=name_base + '1/bn_3')(X)\n    X = Activation('relu', name=name_base + '1/relu_3')(X)\n    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_3', kernel_initializer=glorot_uniform(seed=0))(X)    \n    \n    # Final step: Add Branch1 and the original Input itself\n    X = Add(name=base + '/Add')([X, X_shortcut])\n\n    return X\n\ndef Trunk_block(X, F, base):\n    \n    name_base = base\n    \n    X = res_identity(X, F, name_base + '/Residual_id_1')\n    X = res_identity(X, F, name_base + '/Residual_id_2')\n    return X\n\ndef interpolation(input_tensor, ref_tensor,name): # resizes input_tensor wrt. ref_tensor\n    H, W = ref_tensor.get_shape()[1], ref_tensor.get_shape()[2]\n    return tf.image.resize_nearest_neighbor(input_tensor, [H.value, W.value],name=name)\n\ndef Attention_1(X, filters, base):    \n    F1, F2, F3 = filters    \n    name_base = base \n    \n    X = res_identity(X, filters, name_base+ '/Pre_Residual_id')    \n    X_Trunk = Trunk_block(X, filters, name_base+ '/Trunk')    \n    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_3')(X)    \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_3_Down')    \n    Residual_id_3_Down_shortcut = X    \n    Residual_id_3_Down_branched = res_identity(X, filters, name_base+ '/Mask/Residual_id_3_Down_branched')    \n    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_2')(X)    \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down')    \n    Residual_id_2_Down_shortcut = X    \n    Residual_id_2_Down_branched = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down_branched')    \n    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_1')(X)    \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Down')    \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Up')    \n    temp_name1 = name_base+ \"/Mask/Interpool_1\" \n    X = Lambda(interpolation, arguments={'ref_tensor': Residual_id_2_Down_shortcut,'name':temp_name1})(X)                                          \n    X = Add(name=base + '/Mask/Add_after_Interpool_1')([X, Residual_id_2_Down_branched])                                          \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Up')    \n    temp_name2 = name_base+ \"/Mask/Interpool_2\"   \n    X = Lambda(interpolation, arguments={'ref_tensor': Residual_id_3_Down_shortcut,'name':temp_name2})(X)                                          \n    X = Add(name=base + '/Mask/Add_after_Interpool_2')([X, Residual_id_3_Down_branched])                                          \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_3_Up')   \n    temp_name3 = name_base+ \"/Mask/Interpool_3\"   \n    X = Lambda(interpolation, arguments={'ref_tensor': X_Trunk,'name':temp_name3})(X)                                          \n    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_3/bn_1')(X)                                          \n    X = Activation('relu', name=name_base + '/Mask/Interpool_3/relu_1')(X)                                          \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_3/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)    \n    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_3/bn_2')(X)                                          \n    X = Activation('relu', name=name_base + '/Mask/Interpool_3/relu_2')(X)                                          \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_3/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)    \n    X = Activation('sigmoid', name=name_base+'/Mask/sigmoid')(X)      \n    X = Multiply(name=name_base+'/Mutiply')([X_Trunk,X])    \n    X = Add(name=name_base+'/Add')([X_Trunk,X])\n    X = res_identity(X, filters, name_base+ '/Post_Residual_id')    \n    return X\n\ndef Attention_2(X, filters, base):    \n    F1, F2, F3 = filters   \n    name_base = base  \n    \n    X = res_identity(X, filters, name_base+ '/Pre_Residual_id')    \n    X_Trunk = Trunk_block(X, filters, name_base+ '/Trunk')    \n    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_2')(X)    \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down')    \n    Residual_id_2_Down_shortcut = X    \n    Residual_id_2_Down_branched = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down_branched')    \n    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_1')(X)    \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Down')                                          \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Up')    \n    temp_name1 = name_base+ \"/Mask/Interpool_1\"    \n    X = Lambda(interpolation, arguments={'ref_tensor': Residual_id_2_Down_shortcut,'name':temp_name1})(X)                                          \n    X = Add(name=base + '/Mask/Add_after_Interpool_1')([X, Residual_id_2_Down_branched])                                          \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Up')    \n    temp_name2 = name_base+ \"/Mask/Interpool_2\"    \n    X = Lambda(interpolation, arguments={'ref_tensor': X_Trunk,'name':temp_name2})(X)                                          \n    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_1')(X)                                          \n    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_1')(X)                                          \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)    \n    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_2')(X)                                          \n    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_2')(X)                                          \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)    \n    X = Activation('sigmoid', name=name_base+'/Mask/sigmoid')(X)      \n    X = Multiply(name=name_base+'/Mutiply')([X_Trunk,X])    \n    X = Add(name=name_base+'/Add')([X_Trunk,X])\n    X = res_identity(X, filters, name_base+ '/Post_Residual_id')    \n    return X\n\ndef Attention_3(X, filters, base):    \n    F1, F2, F3 = filters    \n    name_base = base    \n    \n    X = res_identity(X, filters, name_base+ '/Pre_Residual_id')    \n    X_Trunk = Trunk_block(X, filters, name_base+ '/Trunk')    \n    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_1')(X)    \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Down')                                          \n    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Up')    \n    temp_name2 = name_base+ \"/Mask/Interpool_1\"    \n    X = Lambda(interpolation, arguments={'ref_tensor': X_Trunk,'name':temp_name2})(X)                                          \n    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_1')(X)                                          \n    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_1')(X)                                          \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)    \n    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_2')(X)                                          \n    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_2')(X)                                         \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)    \n    X = Activation('sigmoid', name=name_base+'/Mask/sigmoid')(X)      \n    X = Multiply(name=name_base+'/Mutiply')([X_Trunk,X])    \n    X = Add(name=name_base+'/Add')([X_Trunk,X])\n    X = res_identity(X, filters, name_base+ '/Post_Residual_id')  \n    return X","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = ResNet50V2(include_top=False,\n                 weights=None,\n                 input_tensor=input_tensor)\n\n    base_model.load_weights('../input/keras-pretrain-model-weights/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    X = Conv2D(64, (7,7), strides=(2,2), padding='same', name='conv_1', kernel_initializer=glorot_uniform(seed=0))(base_model.output)\n    X = BatchNormalization(axis=-1, name='bn_1')(X)\n    X = Activation('relu', name='relu_1')(X)\n    X = MaxPooling2D((3,3), strides=(2,2), padding='same' ,name='pool_1')(X)\n    X = res_conv(X, [64,64,256], 'Residual_conv_1', 1)\n\n    ### Attention 1 Start\n    X = Attention_1(X, [64,64,256], 'Attention_1')\n    ### Attention 1 End\n\n#     X = res_conv(X, [128,128,512], 'Residual_conv_2', 2)\n\n#     ### Attention 2 Start\n#     X = Attention_2(X, [128,128,512], 'Attention_2')\n#     ### Attention 2 End\n\n#     X = res_conv(X, [256,256,1024], 'Residual_conv_3', 2)\n\n#     ### Attention 3 Start\n#     X = Attention_3(X, [256,256,1024], 'Attention_3')\n#     ### Attention 3 End\n\n    X = res_conv(X, [512,512,2048], 'Residual_conv_4', 2)\n\n    X = res_identity(X, [512,512,2048], 'Residual_id_1')\n    X = res_identity(X, [512,512,2048], 'Residual_id_2')\n    X = BatchNormalization(axis=-1, name='bn_2')(X)\n    X = Activation('relu', name='relu_2')(X)\n    X = GlobalAveragePooling2D()(X)\n    X = Dense(NUM_CLASSES, name='Dense_1')(X)\n    X = Activation('sigmoid', name='classifier')(X)\n\n    model = Model(inputs=input_tensor, outputs=X, name='ResnetV2_final')\n    \n    return model","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# warm up model\nmodel = create_model(\n    input_shape=(SIZE,SIZE,3), \n    n_out=NUM_CLASSES)\n\n# for layer in model.layers:\n#     layer.trainable = False\n\nfor i in range(-201,0):\n    model.layers[i].trainable = True\n\nmodel.compile(loss='binary_crossentropy',\n              metrics=['acc',f2],\n    optimizer=Adam(LR_WARM))\n\nmodel.summary()","execution_count":16,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 200, 200, 3)  0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 206, 206, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 100, 100, 64) 9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 102, 102, 64) 0           conv1_conv[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 50, 50, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_preact_bn (BatchNo (None, 50, 50, 64)   256         pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_preact_relu (Activ (None, 50, 50, 64)   0           conv2_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 50, 50, 64)   4096        conv2_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 50, 50, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_pad (ZeroPadding (None, 52, 52, 64)   0           conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 50, 50, 64)   36864       conv2_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 50, 50, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_out (Add)          (None, 50, 50, 256)  0           conv2_block1_0_conv[0][0]        \n                                                                 conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_preact_bn (BatchNo (None, 50, 50, 256)  1024        conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_preact_relu (Activ (None, 50, 50, 256)  0           conv2_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 50, 50, 64)   16384       conv2_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 50, 50, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_pad (ZeroPadding (None, 52, 52, 64)   0           conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 50, 50, 64)   36864       conv2_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 50, 50, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_out (Add)          (None, 50, 50, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_preact_bn (BatchNo (None, 50, 50, 256)  1024        conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_preact_relu (Activ (None, 50, 50, 256)  0           conv2_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 50, 50, 64)   16384       conv2_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 50, 50, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_pad (ZeroPadding (None, 52, 52, 64)   0           conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36864       conv2_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_out (Add)          (None, 25, 25, 256)  0           max_pooling2d_1[0][0]            \n                                                                 conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_preact_bn (BatchNo (None, 25, 25, 256)  1024        conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_preact_relu (Activ (None, 25, 25, 256)  0           conv3_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 25, 25, 128)  32768       conv3_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 25, 25, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 25, 25, 128)  147456      conv3_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 25, 25, 128)  0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 25, 25, 512)  131584      conv3_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_out (Add)          (None, 25, 25, 512)  0           conv3_block1_0_conv[0][0]        \n                                                                 conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_preact_bn (BatchNo (None, 25, 25, 512)  2048        conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_preact_relu (Activ (None, 25, 25, 512)  0           conv3_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 25, 25, 128)  65536       conv3_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 25, 25, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 25, 25, 128)  147456      conv3_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 25, 25, 128)  0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_out (Add)          (None, 25, 25, 512)  0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_preact_bn (BatchNo (None, 25, 25, 512)  2048        conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_preact_relu (Activ (None, 25, 25, 512)  0           conv3_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 25, 25, 128)  65536       conv3_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 25, 25, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 25, 25, 128)  147456      conv3_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 25, 25, 128)  0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_out (Add)          (None, 25, 25, 512)  0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_preact_bn (BatchNo (None, 25, 25, 512)  2048        conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_preact_relu (Activ (None, 25, 25, 512)  0           conv3_block4_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 25, 25, 128)  65536       conv3_block4_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 25, 25, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147456      conv3_block4_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_out (Add)          (None, 13, 13, 512)  0           max_pooling2d_2[0][0]            \n                                                                 conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_preact_bn (BatchNo (None, 13, 13, 512)  2048        conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_preact_relu (Activ (None, 13, 13, 512)  0           conv4_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 13, 13, 256)  131072      conv4_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 13, 13, 256)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 13, 13, 256)  0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 13, 13, 1024) 525312      conv4_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_out (Add)          (None, 13, 13, 1024) 0           conv4_block1_0_conv[0][0]        \n                                                                 conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 13, 13, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 13, 13, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_out (Add)          (None, 13, 13, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 13, 13, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 13, 13, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_out (Add)          (None, 13, 13, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block4_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block4_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 13, 13, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block4_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 13, 13, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_out (Add)          (None, 13, 13, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block5_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block5_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 13, 13, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block5_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 13, 13, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_out (Add)          (None, 13, 13, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block6_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block6_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 13, 13, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_3[0][0]            \n                                                                 conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n                                                                 conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\npost_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n__________________________________________________________________________________________________\npost_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n__________________________________________________________________________________________________\nconv_1 (Conv2D)                 (None, 4, 4, 64)     6422592     post_relu[0][0]                  \n__________________________________________________________________________________________________\nbn_1 (BatchNormalization)       (None, 4, 4, 64)     256         conv_1[0][0]                     \n__________________________________________________________________________________________________\nrelu_1 (Activation)             (None, 4, 4, 64)     0           bn_1[0][0]                       \n__________________________________________________________________________________________________\npool_1 (MaxPooling2D)           (None, 2, 2, 64)     0           relu_1[0][0]                     \n__________________________________________________________________________________________________\nResidual_conv_1/branch1/bn_1 (B (None, 2, 2, 64)     256         pool_1[0][0]                     \n__________________________________________________________________________________________________\nResidual_conv_1/branch1/relu_1  (None, 2, 2, 64)     0           Residual_conv_1/branch1/bn_1[0][0\n__________________________________________________________________________________________________\nResidual_conv_1/branch1/conv_1  (None, 2, 2, 64)     4160        Residual_conv_1/branch1/relu_1[0]\n__________________________________________________________________________________________________\nResidual_conv_1/branch1/bn_2 (B (None, 2, 2, 64)     256         Residual_conv_1/branch1/conv_1[0]\n__________________________________________________________________________________________________\nResidual_conv_1/branch1/relu_2  (None, 2, 2, 64)     0           Residual_conv_1/branch1/bn_2[0][0\n__________________________________________________________________________________________________\nResidual_conv_1/branch1/conv_2  (None, 2, 2, 64)     36928       Residual_conv_1/branch1/relu_2[0]\n__________________________________________________________________________________________________\nResidual_conv_1/branch1/bn_3 (B (None, 2, 2, 64)     256         Residual_conv_1/branch1/conv_2[0]\n__________________________________________________________________________________________________\nResidual_conv_1/branch2/bn_1 (B (None, 2, 2, 64)     256         pool_1[0][0]                     \n__________________________________________________________________________________________________\nResidual_conv_1/branch1/relu_3  (None, 2, 2, 64)     0           Residual_conv_1/branch1/bn_3[0][0\n__________________________________________________________________________________________________\nResidual_conv_1/branch2/relu_1  (None, 2, 2, 64)     0           Residual_conv_1/branch2/bn_1[0][0\n__________________________________________________________________________________________________\nResidual_conv_1/branch1/conv_3  (None, 2, 2, 256)    16640       Residual_conv_1/branch1/relu_3[0]\n__________________________________________________________________________________________________\nResidual_conv_1/branch2/conv_1  (None, 2, 2, 256)    16640       Residual_conv_1/branch2/relu_1[0]\n__________________________________________________________________________________________________\nResidual_conv_1/Add (Add)       (None, 2, 2, 256)    0           Residual_conv_1/branch1/conv_3[0]\n                                                                 Residual_conv_1/branch2/conv_1[0]\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 256)    1024        Residual_conv_1/Add[0][0]        \n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 256)    0           Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 64)     16448       Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 64)     256         Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 64)     0           Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 64)     36928       Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 64)     256         Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 64)     0           Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/bra (None, 2, 2, 256)    16640       Attention_1/Pre_Residual_id/branc\n__________________________________________________________________________________________________\nAttention_1/Pre_Residual_id/Add (None, 2, 2, 256)    0           Attention_1/Pre_Residual_id/branc\n                                                                 Residual_conv_1/Add[0][0]        \n__________________________________________________________________________________________________\nAttention_1/Mask/pool_3 (MaxPoo (None, 1, 1, 256)    0           Attention_1/Pre_Residual_id/Add[0\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    1024        Attention_1/Mask/pool_3[0][0]    \n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_3_Do\n                                                                 Attention_1/Mask/pool_3[0][0]    \n__________________________________________________________________________________________________\nAttention_1/Mask/pool_2 (MaxPoo (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    1024        Attention_1/Mask/pool_2[0][0]    \n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Do\n                                                                 Attention_1/Mask/pool_2[0][0]    \n__________________________________________________________________________________________________\nAttention_1/Mask/pool_1 (MaxPoo (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    1024        Attention_1/Mask/pool_1[0][0]    \n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_1_Do\n                                                                 Attention_1/Mask/pool_1[0][0]    \n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    1024        Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    1024        Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_1_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_1_Up\n                                                                 Attention_1/Mask/Residual_id_1_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_1_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Do\n                                                                 Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Add_after_Inte (None, 1, 1, 256)    0           lambda_1[0][0]                   \n                                                                 Attention_1/Mask/Residual_id_2_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    1024        Attention_1/Mask/Add_after_Interp\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    1024        Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_2_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Up\n                                                                 Attention_1/Mask/Add_after_Interp\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 256)    1024        Attention_1/Pre_Residual_id/Add[0\n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_2_Up\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_3_Do\n                                                                 Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 256)    0           Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Add_after_Inte (None, 1, 1, 256)    0           lambda_2[0][0]                   \n                                                                 Attention_1/Mask/Residual_id_3_Do\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 64)     16448       Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    1024        Attention_1/Mask/Add_after_Interp\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 64)     256         Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 64)     0           Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     16448       Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 64)     36928       Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 64)     256         Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 64)     0           Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     36928       Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 256)    16640       Attention_1/Trunk/Residual_id_1/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     256         Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_1 (None, 2, 2, 256)    0           Attention_1/Trunk/Residual_id_1/b\n                                                                 Attention_1/Pre_Residual_id/Add[0\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 64)     0           Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 256)    1024        Attention_1/Trunk/Residual_id_1/A\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    16640       Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 256)    0           Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Residual_id_3_ (None, 1, 1, 256)    0           Attention_1/Mask/Residual_id_3_Up\n                                                                 Attention_1/Mask/Add_after_Interp\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 64)     16448       Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 2, 2, 256)    0           Attention_1/Mask/Residual_id_3_Up\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 64)     256         Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Interpool_3/bn (None, 2, 2, 256)    1024        lambda_3[0][0]                   \n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 64)     0           Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Interpool_3/re (None, 2, 2, 256)    0           Attention_1/Mask/Interpool_3/bn_1\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 64)     36928       Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Interpool_3/co (None, 2, 2, 256)    65792       Attention_1/Mask/Interpool_3/relu\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 64)     256         Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Interpool_3/bn (None, 2, 2, 256)    1024        Attention_1/Mask/Interpool_3/conv\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 64)     0           Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Interpool_3/re (None, 2, 2, 256)    0           Attention_1/Mask/Interpool_3/bn_2\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 256)    16640       Attention_1/Trunk/Residual_id_2/b\n__________________________________________________________________________________________________\nAttention_1/Mask/Interpool_3/co (None, 2, 2, 256)    65792       Attention_1/Mask/Interpool_3/relu\n__________________________________________________________________________________________________\nAttention_1/Trunk/Residual_id_2 (None, 2, 2, 256)    0           Attention_1/Trunk/Residual_id_2/b\n                                                                 Attention_1/Trunk/Residual_id_1/A\n__________________________________________________________________________________________________\nAttention_1/Mask/sigmoid (Activ (None, 2, 2, 256)    0           Attention_1/Mask/Interpool_3/conv\n__________________________________________________________________________________________________\nAttention_1/Mutiply (Multiply)  (None, 2, 2, 256)    0           Attention_1/Trunk/Residual_id_2/A\n                                                                 Attention_1/Mask/sigmoid[0][0]   \n__________________________________________________________________________________________________\nAttention_1/Add (Add)           (None, 2, 2, 256)    0           Attention_1/Trunk/Residual_id_2/A\n                                                                 Attention_1/Mutiply[0][0]        \n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 256)    1024        Attention_1/Add[0][0]            \n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 256)    0           Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 64)     16448       Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 64)     256         Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 64)     0           Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 64)     36928       Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 64)     256         Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 64)     0           Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/br (None, 2, 2, 256)    16640       Attention_1/Post_Residual_id/bran\n__________________________________________________________________________________________________\nAttention_1/Post_Residual_id/Ad (None, 2, 2, 256)    0           Attention_1/Post_Residual_id/bran\n                                                                 Attention_1/Add[0][0]            \n__________________________________________________________________________________________________\nResidual_conv_4/branch1/bn_1 (B (None, 2, 2, 256)    1024        Attention_1/Post_Residual_id/Add[\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/relu_1  (None, 2, 2, 256)    0           Residual_conv_4/branch1/bn_1[0][0\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/conv_1  (None, 2, 2, 512)    131584      Residual_conv_4/branch1/relu_1[0]\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/bn_2 (B (None, 2, 2, 512)    2048        Residual_conv_4/branch1/conv_1[0]\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/relu_2  (None, 2, 2, 512)    0           Residual_conv_4/branch1/bn_2[0][0\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/conv_2  (None, 1, 1, 512)    2359808     Residual_conv_4/branch1/relu_2[0]\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/bn_3 (B (None, 1, 1, 512)    2048        Residual_conv_4/branch1/conv_2[0]\n__________________________________________________________________________________________________\nResidual_conv_4/branch2/bn_1 (B (None, 2, 2, 256)    1024        Attention_1/Post_Residual_id/Add[\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/relu_3  (None, 1, 1, 512)    0           Residual_conv_4/branch1/bn_3[0][0\n__________________________________________________________________________________________________\nResidual_conv_4/branch2/relu_1  (None, 2, 2, 256)    0           Residual_conv_4/branch2/bn_1[0][0\n__________________________________________________________________________________________________\nResidual_conv_4/branch1/conv_3  (None, 1, 1, 2048)   1050624     Residual_conv_4/branch1/relu_3[0]\n__________________________________________________________________________________________________\nResidual_conv_4/branch2/conv_1  (None, 1, 1, 2048)   526336      Residual_conv_4/branch2/relu_1[0]\n__________________________________________________________________________________________________\nResidual_conv_4/Add (Add)       (None, 1, 1, 2048)   0           Residual_conv_4/branch1/conv_3[0]\n                                                                 Residual_conv_4/branch2/conv_1[0]\n__________________________________________________________________________________________________\nResidual_id_1/branch1/bn_1 (Bat (None, 1, 1, 2048)   8192        Residual_conv_4/Add[0][0]        \n__________________________________________________________________________________________________\nResidual_id_1/branch1/relu_1 (A (None, 1, 1, 2048)   0           Residual_id_1/branch1/bn_1[0][0] \n__________________________________________________________________________________________________\nResidual_id_1/branch1/conv_1 (C (None, 1, 1, 512)    1049088     Residual_id_1/branch1/relu_1[0][0\n__________________________________________________________________________________________________\nResidual_id_1/branch1/bn_2 (Bat (None, 1, 1, 512)    2048        Residual_id_1/branch1/conv_1[0][0\n__________________________________________________________________________________________________\nResidual_id_1/branch1/relu_2 (A (None, 1, 1, 512)    0           Residual_id_1/branch1/bn_2[0][0] \n__________________________________________________________________________________________________\nResidual_id_1/branch1/conv_2 (C (None, 1, 1, 512)    2359808     Residual_id_1/branch1/relu_2[0][0\n__________________________________________________________________________________________________\nResidual_id_1/branch1/bn_3 (Bat (None, 1, 1, 512)    2048        Residual_id_1/branch1/conv_2[0][0\n__________________________________________________________________________________________________\nResidual_id_1/branch1/relu_3 (A (None, 1, 1, 512)    0           Residual_id_1/branch1/bn_3[0][0] \n__________________________________________________________________________________________________\nResidual_id_1/branch1/conv_3 (C (None, 1, 1, 2048)   1050624     Residual_id_1/branch1/relu_3[0][0\n__________________________________________________________________________________________________\nResidual_id_1/Add (Add)         (None, 1, 1, 2048)   0           Residual_id_1/branch1/conv_3[0][0\n                                                                 Residual_conv_4/Add[0][0]        \n__________________________________________________________________________________________________\nResidual_id_2/branch1/bn_1 (Bat (None, 1, 1, 2048)   8192        Residual_id_1/Add[0][0]          \n__________________________________________________________________________________________________\nResidual_id_2/branch1/relu_1 (A (None, 1, 1, 2048)   0           Residual_id_2/branch1/bn_1[0][0] \n__________________________________________________________________________________________________\nResidual_id_2/branch1/conv_1 (C (None, 1, 1, 512)    1049088     Residual_id_2/branch1/relu_1[0][0\n__________________________________________________________________________________________________\nResidual_id_2/branch1/bn_2 (Bat (None, 1, 1, 512)    2048        Residual_id_2/branch1/conv_1[0][0\n__________________________________________________________________________________________________\nResidual_id_2/branch1/relu_2 (A (None, 1, 1, 512)    0           Residual_id_2/branch1/bn_2[0][0] \n__________________________________________________________________________________________________\nResidual_id_2/branch1/conv_2 (C (None, 1, 1, 512)    2359808     Residual_id_2/branch1/relu_2[0][0\n__________________________________________________________________________________________________\nResidual_id_2/branch1/bn_3 (Bat (None, 1, 1, 512)    2048        Residual_id_2/branch1/conv_2[0][0\n__________________________________________________________________________________________________\nResidual_id_2/branch1/relu_3 (A (None, 1, 1, 512)    0           Residual_id_2/branch1/bn_3[0][0] \n__________________________________________________________________________________________________\nResidual_id_2/branch1/conv_3 (C (None, 1, 1, 2048)   1050624     Residual_id_2/branch1/relu_3[0][0\n__________________________________________________________________________________________________\nResidual_id_2/Add (Add)         (None, 1, 1, 2048)   0           Residual_id_2/branch1/conv_3[0][0\n                                                                 Residual_id_1/Add[0][0]          \n__________________________________________________________________________________________________\nbn_2 (BatchNormalization)       (None, 1, 1, 2048)   8192        Residual_id_2/Add[0][0]          \n__________________________________________________________________________________________________\nrelu_2 (Activation)             (None, 1, 1, 2048)   0           bn_2[0][0]                       \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 2048)         0           relu_2[0][0]                     \n__________________________________________________________________________________________________\nDense_1 (Dense)                 (None, 1103)         2260047     global_average_pooling2d_1[0][0] \n__________________________________________________________________________________________________\nclassifier (Activation)         (None, 1103)         0           Dense_1[0][0]                    \n==================================================================================================\nTotal params: 46,341,647\nTrainable params: 26,161,551\nNon-trainable params: 20,180,096\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(\n    train_generator_warmup,\n    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n    epochs=2,\n    max_queue_size=16, workers=WORKERS, use_multiprocessing=True,\n    verbose=1)","execution_count":17,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/2\n1935/1935 [==============================] - 693s 358ms/step - loss: 0.0141 - acc: 0.9968 - f2: 0.0064\nEpoch 2/2\n1935/1935 [==============================] - 680s 351ms/step - loss: 0.0123 - acc: 0.9972 - f2: 0.0081\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"<keras.callbacks.History at 0x7f39285ea550>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(K.eval(model.optimizer.lr))","execution_count":18,"outputs":[{"output_type":"stream","text":"0.001\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = True\n\nmodel.compile(# loss='binary_crossentropy',\n            loss=focal_loss,\n            optimizer=Adam(lr=LR),\n            metrics=['acc',f2])\n\nhist = model.fit_generator(\n    train_generator,\n    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n    validation_data=validation_generator,\n    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n    epochs=14,\n    verbose=1,\n    max_queue_size=16, workers=WORKERS, use_multiprocessing=True,\n    callbacks=callbacks_list)","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 1/14\n1935/1935 [==============================] - 1127s 583ms/step - loss: 7.9921 - acc: 0.0802 - f2: 0.0074 - val_loss: 9.8090 - val_acc: 0.0150 - val_f2: 0.0056\n\nEpoch 00001: val_loss improved from inf to 9.80897, saving model to ../working/Resnet50_focal.h5\nEpoch 2/14\n1935/1935 [==============================] - 1108s 573ms/step - loss: 8.1753 - acc: 0.0567 - f2: 0.0062 - val_loss: 8.4083 - val_acc: 0.0146 - val_f2: 0.0054\n\nEpoch 00002: val_loss improved from 9.80897 to 8.40829, saving model to ../working/Resnet50_focal.h5\nEpoch 3/14\n1935/1935 [==============================] - 1070s 553ms/step - loss: 7.8755 - acc: 0.0797 - f2: 0.0070 - val_loss: 8.1235 - val_acc: 0.0467 - val_f2: 0.0065\n\nEpoch 00003: val_loss improved from 8.40829 to 8.12347, saving model to ../working/Resnet50_focal.h5\nEpoch 4/14\n1935/1935 [==============================] - 980s 506ms/step - loss: 7.7504 - acc: 0.0820 - f2: 0.0074 - val_loss: 8.1340 - val_acc: 0.0920 - val_f2: 0.0068\n\nEpoch 00004: val_loss did not improve from 8.12347\nEpoch 5/14\n1935/1935 [==============================] - 982s 508ms/step - loss: 7.7975 - acc: 0.0806 - f2: 0.0073 - val_loss: 10.4558 - val_acc: 0.0160 - val_f2: 0.0056\n\nEpoch 00005: val_loss did not improve from 8.12347\nEpoch 6/14\n1935/1935 [==============================] - 1032s 533ms/step - loss: 7.8055 - acc: 0.0845 - f2: 0.0074 - val_loss: 9.0039 - val_acc: 0.0555 - val_f2: 0.0053\n\nEpoch 00006: val_loss did not improve from 8.12347\nEpoch 7/14\n1935/1935 [==============================] - 983s 508ms/step - loss: 7.9103 - acc: 0.0778 - f2: 0.0070 - val_loss: 11.3788 - val_acc: 0.0157 - val_f2: 0.0052\n\nEpoch 00007: val_loss did not improve from 8.12347\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 8/14\n1935/1935 [==============================] - 976s 504ms/step - loss: 7.9153 - acc: 0.0831 - f2: 0.0069 - val_loss: 8.4599 - val_acc: 0.0571 - val_f2: 0.0060\n\nEpoch 00008: val_loss did not improve from 8.12347\nEpoch 9/14\n1935/1935 [==============================] - 963s 498ms/step - loss: 7.8596 - acc: 0.0814 - f2: 0.0071 - val_loss: 8.6851 - val_acc: 0.0629 - val_f2: 0.0061\n\nEpoch 00009: val_loss did not improve from 8.12347\nEpoch 10/14\n1935/1935 [==============================] - 972s 502ms/step - loss: 7.8240 - acc: 0.0850 - f2: 0.0072 - val_loss: 8.7885 - val_acc: 0.0937 - val_f2: 0.0058\n\nEpoch 00010: val_loss did not improve from 8.12347\nEpoch 11/14\n1935/1935 [==============================] - 966s 499ms/step - loss: 8.1404 - acc: 0.0641 - f2: 0.0063 - val_loss: 9.3477 - val_acc: 0.0216 - val_f2: 0.0055\n\nEpoch 00011: val_loss did not improve from 8.12347\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 12/14\n1935/1935 [==============================] - 977s 505ms/step - loss: 7.7981 - acc: 0.0814 - f2: 0.0072 - val_loss: 8.7584 - val_acc: 0.0303 - val_f2: 0.0058\n\nEpoch 00012: val_loss did not improve from 8.12347\nEpoch 13/14\n1935/1935 [==============================] - 968s 500ms/step - loss: 7.6519 - acc: 0.0915 - f2: 0.0076 - val_loss: 8.7711 - val_acc: 0.0461 - val_f2: 0.0064\n\nEpoch 00013: val_loss did not improve from 8.12347\nEpoch 14/14\n1935/1935 [==============================] - 1009s 521ms/step - loss: 7.5659 - acc: 0.1017 - f2: 0.0080 - val_loss: 8.4324 - val_acc: 0.0558 - val_f2: 0.0063\n\nEpoch 00014: val_loss did not improve from 8.12347\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(15,5))\nax[0].set_title('loss')\nax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\nax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\nax[1].set_title('f2')\nax[1].plot(hist.epoch, hist.history[\"f2\"], label=\"Train F2\")\nax[1].plot(hist.epoch, hist.history[\"val_f2\"], label=\"Validation F2\")\nax[0].legend()\nax[1].legend()","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"<matplotlib.legend.Legend at 0x7f390386ff28>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x360 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(K.eval(model.optimizer.lr))","execution_count":21,"outputs":[{"output_type":"stream","text":"2.5e-05\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../working/'))\n# model.load_weights(checkpoint_file)","execution_count":22,"outputs":[{"output_type":"stream","text":"['__notebook_source__.ipynb', 'training_log.csv', '.ipynb_checkpoints', 'Resnet50_focal.h5']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Search for the best threshold regarding the validation set'''\n\nBATCH = 512\nfullValGen = data_generator.create_valid(\n    train_dataset_info[valid_indexes], BATCH, (SIZE,SIZE,3))\n\nn_val = round(train_dataset_info.shape[0]*0.2)//BATCH\nprint(n_val)\n\nlastFullValPred = np.empty((0, NUM_CLASSES))\nlastFullValLabels = np.empty((0, NUM_CLASSES))\nfor i in tqdm(range(n_val+1)): \n    im, lbl = next(fullValGen)\n    scores = model.predict(im)\n    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\nprint(lastFullValPred.shape, lastFullValLabels.shape)","execution_count":23,"outputs":[{"output_type":"stream","text":"\r  0%|          | 0/43 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"42\n","name":"stdout"},{"output_type":"stream","text":"100%|| 43/43 [03:11<00:00,  4.67s/it]","name":"stderr"},{"output_type":"stream","text":"(21506, 1103) (21506, 1103)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_f2(y_true, y_pred):\n    assert y_true.shape[0] == y_pred.shape[0]\n\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    tn = np.sum((y_true == 0) & (y_pred == 0))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    \n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f2 = (1+beta_f2**2)*p*r / (p*beta_f2**2 + r + 1e-15)\n\n    return f2\n\ndef find_best_fixed_threshold(preds, targs, do_plot=True):\n    score = []\n    thrs = np.arange(0, 0.5, 0.01)\n    for thr in tqdm(thrs):\n        score.append(my_f2(targs, (preds > thr).astype(int) ))\n    score = np.array(score)\n    pm = score.argmax()\n    best_thr, best_score = thrs[pm], score[pm].item()\n    print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n    if do_plot:\n        plt.plot(thrs, score)\n        plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n        plt.text(best_thr+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n        plt.show()\n    return best_thr, best_score","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_thr, best_score = find_best_fixed_threshold(lastFullValPred, lastFullValLabels, do_plot=True)","execution_count":25,"outputs":[{"output_type":"stream","text":"100%|| 50/50 [00:22<00:00,  2.24it/s]\n","name":"stderr"},{"output_type":"stream","text":"thr=0.170 F2=0.235\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/imet-2019-fgvc6/sample_submission.csv')\npredicted = []\n\nfor i, name in tqdm(enumerate(submit['id'])):\n    path = os.path.join('../input/imet-2019-fgvc6/test/', name)\n    image = data_generator.load_image(path, (SIZE,SIZE,3))\n    score_predict = model.predict(preprocess_input(image[np.newaxis]))\n    # print(score_predict)\n    label_predict = np.arange(NUM_CLASSES)[score_predict[0]>=best_thr]\n    # print(label_predict)\n    str_predict_label = ' '.join(str(l) for l in label_predict)\n    predicted.append(str_predict_label)","execution_count":null,"outputs":[{"output_type":"stream","text":"5125it [02:25, 35.10it/s]","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit['attribute_ids'] = predicted\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}