{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['xception', 'imet-2019-fgvc6']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score\nfrom keras.utils import Sequence\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSIZE = 256\nNUM_CLASSES = 1103\nbeta_f2=2","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataset info\npath_to_train = '../input/imet-2019-fgvc6/train/'\ndata = pd.read_csv('../input/imet-2019-fgvc6/train.csv')\n\ntrain_dataset_info = []\nfor name, labels in zip(data['id'], data['attribute_ids'].str.split(' ')):\n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n\nclass data_generator(Sequence):\n    \n    def create_train(dataset_info, batch_size, shape, augument=True):\n        assert shape[2] == 3\n        while True:\n            dataset_info = shuffle(dataset_info)\n            for start in range(0, len(dataset_info), batch_size):\n                end = min(start + batch_size, len(dataset_info))\n                batch_images = []\n                X_train_batch = dataset_info[start:end]\n                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n                for i in range(len(X_train_batch)):\n                    image = data_generator.load_image(\n                        X_train_batch[i]['path'], shape)   \n                    if augument:\n                        image = data_generator.augment(image)\n                    batch_images.append(image/255.)\n                    batch_labels[i][X_train_batch[i]['labels']] = 1\n                    \n                yield np.array(batch_images, np.float32), batch_labels\n\n    def create_valid(dataset_info, batch_size, shape, augument=False):\n        assert shape[2] == 3\n        while True:\n            # dataset_info = shuffle(dataset_info)\n            for start in range(0, len(dataset_info), batch_size):\n                end = min(start + batch_size, len(dataset_info))\n                batch_images = []\n                X_train_batch = dataset_info[start:end]\n                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n                for i in range(len(X_train_batch)):\n                    image = data_generator.load_image(\n                        X_train_batch[i]['path'], shape)   \n                    if augument:\n                        image = data_generator.augment(image)\n                    batch_images.append(image/255.)\n                    batch_labels[i][X_train_batch[i]['labels']] = 1\n                yield np.array(batch_images, np.float32), batch_labels\n\n\n    def load_image(path, shape):\n        image = cv2.imread(path+'.png')\n        image = cv2.resize(image, (SIZE, SIZE))\n        return image\n\n    def augment(image):\n        augment_img = iaa.Sequential([\n            iaa.OneOf([\n                iaa.Affine(rotate=0),\n                iaa.Affine(rotate=(-15,15)),\n                iaa.Crop(px=(0, 16)),\n                iaa.Affine(shear=(-5, 5)),\n                iaa.GaussianBlur(sigma=(0, 0.5)),\n                iaa.Fliplr(0.5),\n            ])], random_order=True)\n\n        image_aug = augment_img.augment_image(image)\n        return image_aug\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import *\nfrom keras.applications import *\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport keras\nfrom keras.models import Model\n\nK.set_image_dim_ordering('th')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference link: https://gist.github.com/drscotthawley/d1818aabce8d1bf082a6fb37137473ae\nfrom keras.callbacks import Callback\n\ndef get_1cycle_schedule(lr_max=1e-3, n_data_points=8000, epochs=200, batch_size=40, verbose=0):          \n    \"\"\"\n    Creates a look-up table of learning rates for 1cycle schedule with cosine annealing\n    See @sgugger's & @jeremyhoward's code in fastai library: https://github.com/fastai/fastai/blob/master/fastai/train.py\n    Wrote this to use with my Keras and (non-fastai-)PyTorch codes.\n    Note that in Keras, the LearningRateScheduler callback (https://keras.io/callbacks/#learningratescheduler) only operates once per epoch, not per batch\n      So see below for Keras callback\n\n    Keyword arguments:\n    lr_max            chosen by user after lr_finder\n    n_data_points     data points per epoch (e.g. size of training set)\n    epochs            number of epochs\n    batch_size        batch size\n    Output:  \n    lrs               look-up table of LR's, with length equal to total # of iterations\n    Then you can use this in your PyTorch code by counting iteration number and setting\n          optimizer.param_groups[0]['lr'] = lrs[iter_count]\n    \"\"\"\n    if verbose > 0:\n        print(\"Setting up 1Cycle LR schedule...\")\n    pct_start, div_factor = 0.3, 25.        # @sgugger's parameters in fastai code\n    lr_start = lr_max/div_factor\n    lr_end = lr_start/1e4\n    n_iter = (n_data_points * epochs // batch_size) + 1    # number of iterations\n    a1 = int(n_iter * pct_start)\n    a2 = n_iter - a1\n\n    # make look-up table\n    lrs_first = np.linspace(lr_start, lr_max, a1)            # linear growth\n    lrs_second = (lr_max-lr_end)*(1+np.cos(np.linspace(0,np.pi,a2)))/2 + lr_end  # cosine annealing\n    lrs = np.concatenate((lrs_first, lrs_second))\n    return lrs\n\n\nclass OneCycleScheduler(Callback):\n    \"\"\"My modification of Keras' Learning rate scheduler to do 1Cycle learning\n       which increments per BATCH, not per epoch\n    Keyword arguments\n        **kwargs:  keyword arguments to pass to get_1cycle_schedule()\n        Also, verbose: int. 0: quiet, 1: update messages.\n\n    Sample usage (from my train.py):\n        lrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=X_train.shape[0],\n        epochs=epochs, batch_size=batch_size, verbose=1)\n    \"\"\"\n    def __init__(self, **kwargs):\n        super(OneCycleScheduler, self).__init__()\n        self.verbose = kwargs.get('verbose', 0)\n        self.lrs = get_1cycle_schedule(**kwargs)\n        self.iteration = 0\n\n    def on_batch_begin(self, batch, logs=None):\n        lr = self.lrs[self.iteration]\n        K.set_value(self.model.optimizer.lr, lr)         # here's where the assignment takes place\n        if self.verbose > 0:\n            print('\\nIteration %06d: OneCycleScheduler setting learning '\n                  'rate to %s.' % (self.iteration, lr))\n        self.iteration += 1\n\n    def on_epoch_end(self, epoch, logs=None):  # this is unchanged from Keras LearningRateScheduler\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n        self.iteration = 0\n\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = Xception(include_top=False,\n                   weights=None,\n                   input_tensor=input_tensor)\n    base_model.load_weights('../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    \n    \n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(base_model.output)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Conv2D(256, kernel_size=(1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(512, kernel_size=(1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    \n#     x = Flatten()(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    final_output = Dense(n_out, activation='sigmoid', name='final_output')(x)\n    model = Model(input_tensor, final_output)\n    \n    return model","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create callbacks list\nfrom keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n                             \nfrom sklearn.model_selection import train_test_split\n\nepochs = 7; batch_size = 32\ncheckpoint = ModelCheckpoint('../working/Resnet50_focal.h5', monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n                                   verbose=1, mode='auto', epsilon=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=9)\n\ncsv_logger = CSVLogger(filename='../working/training_log.csv',\n                       separator=',',\n                       append=True)\n\n\n# split data into train, valid\nindexes = np.arange(train_dataset_info.shape[0])\ntrain_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n\n# create train and valid datagens\ntrain_generator = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\ntrain_generator_warmup = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=False)\nvalidation_generator = data_generator.create_valid(\n    train_dataset_info[valid_indexes], batch_size, (SIZE,SIZE,3), augument=False)\n\nlrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=len(train_indexes),\n        epochs=1, batch_size=batch_size, verbose=0)\n# callbacks_list = [checkpoint, csv_logger, lrsched]\ncallbacks_list = [checkpoint, csv_logger, reduceLROnPlat]","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# warm up model\nmodel = create_model(\n    input_shape=(SIZE,SIZE,3), \n    n_out=NUM_CLASSES)","execution_count":10,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_1[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 63, 63, 128)  512         conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 63, 63, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 63, 63, 128)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 256)  32768       add_1[0][0]                      \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_2[0][0]                      \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 16, 16, 728)  186368      add_2[0][0]                      \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 16, 16, 728)  2912        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n                                                                 batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n                                                                 add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_11[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 8, 8, 1024)   745472      add_11[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 8, 8, 1024)   4096        conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_12[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 128, 8, 2048) 1152        block14_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 128, 8, 2048) 8192        conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 128, 8, 2048) 16512       batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 128, 8, 2048) 8192        conv2d_6[0][0]                   \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 128, 8, 2048) 0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 128, 8, 2048) 16512       dropout_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 128, 8, 2048) 8192        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 128, 8, 2048) 16512       batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 128, 8, 2048) 8192        conv2d_8[0][0]                   \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 128, 8, 2048) 0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 256, 8, 2048) 33024       dropout_2[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 256, 8, 2048) 8192        conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 512, 8, 2048) 131584      batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 512, 8, 2048) 8192        conv2d_10[0][0]                  \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 512, 8, 2048) 0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 512)          0           dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 512)          0           global_average_pooling2d_1[0][0] \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1024)         525312      dropout_4[0][0]                  \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n__________________________________________________________________________________________________\nfinal_output (Dense)            (None, 1103)         1130575     dropout_5[0][0]                  \n==================================================================================================\nTotal params: 22,781,815\nTrainable params: 22,702,711\nNon-trainable params: 79,104\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor layer in model.layers:\n    layer.trainable = False\n\nfor i in range(-5,0):\n    model.layers[i].trainable = True\n\nmodel.compile(\n    loss=focal_loss,\n    optimizer=Adam(1e-3))\n\n# model.summary()\n\nmodel.fit_generator(\n    train_generator_warmup,\n    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n    validation_data=validation_generator,\n    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n    epochs=epochs,\n    max_queue_size=16, workers=WORKERS, use_multiprocessing=True,\n    verbose=1)","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/7\n2902/2902 [==============================] - 896s 309ms/step - loss: 5.6120 - val_loss: 6.4902\nEpoch 2/7\n2902/2902 [==============================] - 886s 305ms/step - loss: 5.1695 - val_loss: 9.2768\nEpoch 3/7\n2902/2902 [==============================] - 884s 305ms/step - loss: 5.1451 - val_loss: 9.9489\nEpoch 4/7\n2902/2902 [==============================] - 879s 303ms/step - loss: 5.1136 - val_loss: 10.4826\nEpoch 5/7\n2902/2902 [==============================] - 880s 303ms/step - loss: 5.1064 - val_loss: 10.6660\nEpoch 6/7\n2902/2902 [==============================] - 879s 303ms/step - loss: 5.1069 - val_loss: 10.8599\nEpoch 7/7\n2902/2902 [==============================] - 876s 302ms/step - loss: 5.0881 - val_loss: 10.6409\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<keras.callbacks.History at 0x7f19d6c0a668>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../working/'))","execution_count":14,"outputs":[{"output_type":"stream","text":"['__notebook_source__.ipynb', '.ipynb_checkpoints']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/imet-2019-fgvc6/sample_submission.csv')\nmodel.load_weights('../working/Resnet50_focal.h5')\npredicted = []","execution_count":15,"outputs":[{"output_type":"error","ename":"OSError","evalue":"Unable to open file (unable to open file: name = '../working/Resnet50_focal.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-9b690789c162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/imet-2019-fgvc6/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../working/Resnet50_focal.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../working/Resnet50_focal.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Search for the best threshold regarding the validation set'''\n\nBATCH = 512\nfullValGen = data_generator.create_valid(\n    train_dataset_info[valid_indexes], BATCH, (SIZE,SIZE,3))\n\nn_val = round(train_dataset_info.shape[0]*0.15)//BATCH\nprint(n_val)\n\nlastFullValPred = np.empty((0, NUM_CLASSES))\nlastFullValLabels = np.empty((0, NUM_CLASSES))\nfor i in tqdm(range(n_val+1)): \n    im, lbl = next(fullValGen)\n    scores = model.predict(im)\n    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\nprint(lastFullValPred.shape, lastFullValLabels.shape)","execution_count":16,"outputs":[{"output_type":"stream","text":"\r  0%|          | 0/33 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"32\n","name":"stdout"},{"output_type":"stream","text":"100%|| 33/33 [03:52<00:00,  5.30s/it]","name":"stderr"},{"output_type":"stream","text":"(16386, 1103) (16386, 1103)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_f2(y_true, y_pred):\n    assert y_true.shape[0] == y_pred.shape[0]\n\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    tn = np.sum((y_true == 0) & (y_pred == 0))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    \n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f2 = (1+beta_f2**2)*p*r / (p*beta_f2**2 + r + 1e-15)\n\n    return f2\n\ndef find_best_fixed_threshold(preds, targs, do_plot=True):\n    score = []\n    thrs = np.arange(0, 0.5, 0.01)\n    for thr in tqdm(thrs):\n        score.append(my_f2(targs, (preds > thr).astype(int) ))\n    score = np.array(score)\n    pm = score.argmax()\n    best_thr, best_score = thrs[pm], score[pm].item()\n    print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n    if do_plot:\n        plt.plot(thrs, score)\n        plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n        plt.text(best_thr+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n        plt.show()\n    return best_thr, best_score","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_thr, best_score = find_best_fixed_threshold(lastFullValPred, lastFullValLabels, do_plot=True)","execution_count":18,"outputs":[{"output_type":"stream","text":"100%|| 50/50 [00:14<00:00,  3.42it/s]\n","name":"stderr"},{"output_type":"stream","text":"thr=0.080 F2=0.137\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor i, name in tqdm(enumerate(submit['id'])):\n    path = os.path.join('../input/imet-2019-fgvc6/test/', name)\n    image = data_generator.load_image(path, (SIZE,SIZE,3))\n    score_predict = model.predict(image[np.newaxis]/255.)\n    # print(score_predict)\n    label_predict = np.arange(NUM_CLASSES)[score_predict[0]>=best_thr]\n    # print(label_predict)\n    str_predict_label = ' '.join(str(l) for l in label_predict)\n    predicted.append(str_predict_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit['attribute_ids'] = predicted\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}