{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3-E2-BOW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ll1195831146/Infor7374-AI/blob/master/Assignment3/Assignment3_E2_BOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Hm9BHTx2qT43",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fc82adc-8b99-4559-9069-da4c7b15cd9e"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "keras.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "YcyJI9I3qgeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37d96c75-f7b0-43ae-e321-4a0d4c9b7383"
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r2uVBZrbqjvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50c9450b-a49b-444d-8483-6e96d3e985fd"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pG4trikcqmeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "d8b5561a-8d88-4775-d134-7a972197af74"
      },
      "cell_type": "code",
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "#define decoding function\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "#display first review in words\n",
        "decode_review(train_data[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 1us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "cc5H54LOrICA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#make the length of each review array as same\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "geeKeQMJseJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "3ff173d2-8242-48aa-ceb2-bf107ca44573"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yAg_UTCzsgOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "122390d2-31fc-4572-be1a-c8e47fac063f"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'6210 Database Design.gdoc'\t   out_data_train_1.zip\n",
            " 7374Assignment3\t\t   out_data_train.zip\n",
            " aclImdb\t\t\t   out_data_val\n",
            " AED_Lab1_Part1.mp4\t\t   out_data_val_1.zip\n",
            " AED_Lab1_Part2Final.mp4\t   out_data_val.zip\n",
            " Assignment2-E1.ipynb\t\t   resized-tiny-imagenet-200\n",
            " Assignment3.json\t\t   resized-tiny-imagenet-200.zip\n",
            "'Colab Notebooks'\t\t   Resume0306.gdoc\n",
            " data\t\t\t\t   RL-NikBrown.gdoc\n",
            " drive\t\t\t\t   Track-guidelines.pdf\n",
            " Final_test.json\t\t   val_data\n",
            " Final_train.json\t\t   Video_Games_Sales.csv\n",
            " games.zip\t\t\t  'VideoGames-Version2 2.zip'\n",
            " Imagenet32_train\t\t   VideoGames-Version4-2.zip\n",
            "'NBA_stats_f (Recovered).gsheet'   VideoGames-Version4.zip\n",
            " out_data_train\t\t\t   y_val_1.npy\n",
            " out_data_train_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1nAi2XW5tHC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c768ded-1562-46f5-8f1f-83369e63c406"
      },
      "cell_type": "code",
      "source": [
        "os.chdir(os.path.join(os.getcwd(),'drive/My Drive'))\n",
        "print(os.getcwd())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wiZYG4MnrLg_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import tarfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMT0OrOjrRzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59
        },
        "outputId": "c01e9733-a7e6-4a2e-f562-06d96a09663f"
      },
      "cell_type": "code",
      "source": [
        "url=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\" #download url\n",
        "filepath=\"7374Assignment3/aclImdb_v1.tar.gz\"\n",
        "if not os.path.isfile(filepath):\n",
        "  result=urllib.request.urlretrieve(url,filepath)\n",
        "  print('downloaded:',result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloaded: ('7374Assignment3/aclImdb_v1.tar.gz', <http.client.HTTPMessage object at 0x7f921b4aac50>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tj5OKwwCrR2D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"7374Assignment3/aclImdb\"):\n",
        "  tfile = tarfile.open(\"7374Assignment3/aclImdb_v1.tar.gz\", 'r:gz')\n",
        "  result=tfile.extractall('7374Assignment3/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q_-T6ixiuIET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "88c6a467-96a5-4440-add5-77f90247e00b"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_files\n",
        "reviews_train = load_files(\"7374Assignment3/aclImdb/train/\")\n",
        "text_train, y_train = reviews_train.data, reviews_train.target\n",
        "\n",
        "print(\"Number of documents in train data: {}\".format(len(text_train)))\n",
        "print(\"Samples per class (train): {}\".format(np.bincount(y_train)))\n",
        "\n",
        "reviews_test = load_files(\"7374Assignment3/aclImdb/test/\")\n",
        "text_test, y_test = reviews_test.data, reviews_test.target\n",
        "\n",
        "print(\"Number of documents in test data: {}\".format(len(text_test)))\n",
        "print(\"Samples per class (test): {}\".format(np.bincount(y_test)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of documents in train data: 75000\n",
            "Samples per class (train): [12500 12500 50000]\n",
            "Number of documents in test data: 25000\n",
            "Samples per class (test): [12500 12500]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YbX8n86Audcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "56d439c8-0fae-460b-b853-c5270a2becc0"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
        "x_train = vect.fit(text_train).transform(text_train)\n",
        "x_test = vect.transform(text_test)\n",
        "\n",
        "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
        "print(\"X_train:\\n{}\".format(repr(x_train)))\n",
        "print(\"X_test: \\n{}\".format(repr(x_test)))\n",
        "\n",
        "feature_names = vect.get_feature_names()\n",
        "print(\"Number of features: {}\".format(len(feature_names)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 332885\n",
            "X_train:\n",
            "<75000x332885 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 12160550 stored elements in Compressed Sparse Row format>\n",
            "X_test: \n",
            "<25000x332885 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 3852008 stored elements in Compressed Sparse Row format>\n",
            "Number of features: 332885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m9CUJL_z3avx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7p2-hg0e3ayz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = np.max(y_train) + 1\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VTSxJSrwNYOd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "# define network\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_shape=(x_train.shape[1],), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "# compile network\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQhHWRSxNYRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        },
        "outputId": "0dc84902-e7a2-4919-c03c-52f080f1164e"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=5,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 75000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "75000/75000 [==============================] - 306s 4ms/step - loss: 0.5189 - acc: 0.7730 - val_loss: 0.8323 - val_acc: 0.3350\n",
            "Epoch 2/5\n",
            "75000/75000 [==============================] - 305s 4ms/step - loss: 0.3975 - acc: 0.8057 - val_loss: 0.9210 - val_acc: 0.3579\n",
            "Epoch 3/5\n",
            "75000/75000 [==============================] - 303s 4ms/step - loss: 0.2962 - acc: 0.8665 - val_loss: 1.0559 - val_acc: 0.4012\n",
            "Epoch 4/5\n",
            " 8384/75000 [==>...........................] - ETA: 3:43 - loss: 0.2161 - acc: 0.9215"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-95ca7e1279d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SxIO2errNSta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0bcf67c-ab7d-4951-89e5-e4abe42613ff"
      },
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100) + '%')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 39.620001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AH2iQ_Ip5oKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d1d0705-afec-4542-be3a-7551955e4728"
      },
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join(os.getcwd(), '7374Assignment3')\n",
        "model_name = 'keras_BOW_E2_model_v1.h5'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/drive/My Drive/7374Assignment3/keras_BOW_E2_model_v1.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0mQzuzDm4CH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "1f841960-0dd8-4be4-a54d-372b5b82b0cb"
      },
      "cell_type": "code",
      "source": [
        "# visualization\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        " \n",
        "epoch = range(len(acc))\n",
        " \n",
        "plt.plot(epoch, acc, 'b', label='Training acc')\n",
        "plt.plot(epoch, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        " \n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epoch, loss, 'b', label='Training loss')\n",
        "plt.plot(epoch, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-6301d7b8d00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "g2u1v8N36DFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "98d68c09-95b4-489d-e704-8d5cf8e37f2c"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Returns a compiled model identical to the previous one\n",
        "model = load_model('7374Assignment3/keras_BOW_E2_model_v1.h5')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tYrctqyXdZbW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('Final_test.json') as test_f:\n",
        "   test_data = json.load(test_f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0IfwaG0QNXJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = pd.DataFrame(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F9w8Khc0eY05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "431fa31a-8a8e-46d0-c934-09927e27e57f"
      },
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Moving on to taxes. As mentioned earlier, our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Turning to Page 13 on Capital. Our Common Equi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>[Operator Instructions]. Your first question i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>negative</td>\n",
              "      <td>For my follow-up, Jen-Hsun you and Colette, yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>negative</td>\n",
              "      <td>Well, in the short-term, in the near-term, we ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>negative</td>\n",
              "      <td>Second, deteriorating macro economic condition...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>negative</td>\n",
              "      <td>I wanted to ask about again competition and da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>negative</td>\n",
              "      <td>Our data center business is really focused on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>negative</td>\n",
              "      <td>If you think about competitively comparing our...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>positive</td>\n",
              "      <td>And then lastly, because of the broad reach of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>negative</td>\n",
              "      <td>I have just a couple of questions. The first o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Glenn Schorr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>positive</td>\n",
              "      <td>First of all, the Turing architecture is the h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>positive</td>\n",
              "      <td>The cash architecture is a big improvement, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Turing comes with its several new opportunitie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>positive</td>\n",
              "      <td>And to also answer your question regarding DRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Crypto mining demand and its after effects hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Building on the discussion around the Turing p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>positive</td>\n",
              "      <td>First of all, on the pricing part, the biggest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>negative</td>\n",
              "      <td>Could you just -- a clarification. Could you r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>And I want to talk about I&amp;L. And it's a combo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>neutral</td>\n",
              "      <td>I'll start off to repeat what we indicated in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line Mit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>negative</td>\n",
              "      <td>So I don't want to poke too many holes on the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>negative</td>\n",
              "      <td>On your gross margin question, yes we still ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>neutral</td>\n",
              "      <td>All our statements are made as of today, Febru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>positive</td>\n",
              "      <td>With that, I'd like to turn the call over to C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And our first question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Your next question is from C.J. Muse with Ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>negative</td>\n",
              "      <td>Colette, I appreciate all the data you gave us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>positive</td>\n",
              "      <td>I’ll start and I’ll let Jen-Hsun finish that q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>negative</td>\n",
              "      <td>I think your math isn't wrong. The part that y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Operator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And then maybe as a follow-up just on the data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>positive</td>\n",
              "      <td>Thanks, Simona. As you know we lowered fourth ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>negative</td>\n",
              "      <td>We don't see them in high performance computin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>positive</td>\n",
              "      <td>We have four new growth drivers, four new ways...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>neutral</td>\n",
              "      <td>The second way is data analytics. This is a br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>positive</td>\n",
              "      <td>And then lastly, we've been successful with CS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>positive</td>\n",
              "      <td>And so we have four different ways to grow our...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>negative</td>\n",
              "      <td>First, I had a clarification. Colette, I just ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>positive</td>\n",
              "      <td>Our guidance for the next quarter is a make-up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Michael Mayo - Wells Fargo Securities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>positive</td>\n",
              "      <td>Tim, one of the things to keep in mind is that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>positive</td>\n",
              "      <td>We've been investing, as you know, in self-dri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>negative</td>\n",
              "      <td>Starting with our gaming business. Revenue of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>neutral</td>\n",
              "      <td>And your next question comes from the line of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>negative</td>\n",
              "      <td>First, I wanted to get the mix, this is questi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>negative</td>\n",
              "      <td>We'll start with that first question on gross ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>neutral</td>\n",
              "      <td>So what do you think the bigger between those ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>negative</td>\n",
              "      <td>I think it's more on the inter pieces. Now kee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>neutral</td>\n",
              "      <td>So you think it's the mix between the business...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>positive</td>\n",
              "      <td>The mix of the intra, both within the segment ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>264 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                               text\n",
              "0    Negative  Moving on to taxes. As mentioned earlier, our ...\n",
              "1    Positive  Turning to Page 13 on Capital. Our Common Equi...\n",
              "10    Neutral  [Operator Instructions]. Your first question i...\n",
              "100  negative  For my follow-up, Jen-Hsun you and Colette, yo...\n",
              "101  negative  Well, in the short-term, in the near-term, we ...\n",
              "102   neutral  And your next question comes from the line of ...\n",
              "103  negative  Second, deteriorating macro economic condition...\n",
              "104  negative  I wanted to ask about again competition and da...\n",
              "105  negative  Our data center business is really focused on ...\n",
              "106  negative  If you think about competitively comparing our...\n",
              "107  positive  And then lastly, because of the broad reach of...\n",
              "108   neutral  And your next question comes from the line of ...\n",
              "109  negative  I have just a couple of questions. The first o...\n",
              "11    Neutral                                       Glenn Schorr\n",
              "110  positive  First of all, the Turing architecture is the h...\n",
              "111  positive  The cash architecture is a big improvement, an...\n",
              "112   neutral  Turing comes with its several new opportunitie...\n",
              "113  positive  And to also answer your question regarding DRA...\n",
              "114   neutral  Crypto mining demand and its after effects hav...\n",
              "115   neutral  And your next question comes from the line of ...\n",
              "116   neutral  Building on the discussion around the Turing p...\n",
              "117  positive  First of all, on the pricing part, the biggest...\n",
              "118   neutral  And your next question comes from the line of ...\n",
              "119  negative  Could you just -- a clarification. Could you r...\n",
              "12    Neutral  And I want to talk about I&L. And it's a combo...\n",
              "120   neutral  I'll start off to repeat what we indicated in ...\n",
              "121   neutral  And your next question comes from the line Mit...\n",
              "122  negative  So I don't want to poke too many holes on the ...\n",
              "123  negative  On your gross margin question, yes we still ha...\n",
              "124   neutral  And your next question comes from the line of ...\n",
              "..        ...                                                ...\n",
              "72    neutral  All our statements are made as of today, Febru...\n",
              "73   positive  With that, I'd like to turn the call over to C...\n",
              "74    neutral  And our first question comes from the line of ...\n",
              "75    neutral  Your next question is from C.J. Muse with Ever...\n",
              "76    neutral  And your next question comes from the line and...\n",
              "77   negative  Colette, I appreciate all the data you gave us...\n",
              "78   positive  I’ll start and I’ll let Jen-Hsun finish that q...\n",
              "79   negative  I think your math isn't wrong. The part that y...\n",
              "8     Neutral                                           Operator\n",
              "80    neutral  And then maybe as a follow-up just on the data...\n",
              "81   positive  Thanks, Simona. As you know we lowered fourth ...\n",
              "82   negative  We don't see them in high performance computin...\n",
              "83   positive  We have four new growth drivers, four new ways...\n",
              "84    neutral  The second way is data analytics. This is a br...\n",
              "85   positive  And then lastly, we've been successful with CS...\n",
              "86   positive  And so we have four different ways to grow our...\n",
              "87    neutral  And your next question comes from the line of ...\n",
              "88   negative  First, I had a clarification. Colette, I just ...\n",
              "89   positive  Our guidance for the next quarter is a make-up...\n",
              "9     Neutral              Michael Mayo - Wells Fargo Securities\n",
              "90   positive  Tim, one of the things to keep in mind is that...\n",
              "91   positive  We've been investing, as you know, in self-dri...\n",
              "92   negative  Starting with our gaming business. Revenue of ...\n",
              "93    neutral  And your next question comes from the line of ...\n",
              "94   negative  First, I wanted to get the mix, this is questi...\n",
              "95   negative  We'll start with that first question on gross ...\n",
              "96    neutral  So what do you think the bigger between those ...\n",
              "97   negative  I think it's more on the inter pieces. Now kee...\n",
              "98    neutral  So you think it's the mix between the business...\n",
              "99   positive  The mix of the intra, both within the segment ...\n",
              "\n",
              "[264 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "vlNmZXsneaJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data['sentiment'] = test_data['sentiment'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eaulBBmsemTn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = test_data[test_data.sentiment != 'neutral']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jf-MIh43flIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
        "x_train = vect.fit(text_train).transform(text_train)\n",
        "x_test = vect.transform(text_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}