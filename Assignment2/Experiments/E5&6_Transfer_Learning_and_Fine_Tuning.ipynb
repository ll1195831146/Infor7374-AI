{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E5&6-Transfer Learning and Fine Tuning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ll1195831146/Infor7374-AI/blob/master/Assignment2/E5%266_Transfer_Learning_and_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M1l0bzD1g8kp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Convolution2D, \\\n",
        "    GlobalAveragePooling2D, Dense, BatchNormalization, Activation\n",
        "from keras.models import Model\n",
        "from keras.metrics import top_k_categorical_accuracy, categorical_accuracy\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.layers import DepthwiseConv2D\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10 \n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXcSWut_1woi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#base setup\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "data_augmentation = True\n",
        "subtract_pixel_mean = True\n",
        "num_predictions = 20\n",
        "size = 224\n",
        "alpha = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uIZpCV9jE2dz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resize_image_arr(img_arr):\n",
        "    x_resized_list = []\n",
        "    for i in range(img_arr.shape[0]):\n",
        "        img = img_arr[0]\n",
        "        resized_img = resize(img, (size, size))\n",
        "        x_resized_list.append(resized_img)\n",
        "    return np.stack(x_resized_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyJnf2BAhBDS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train[0:2000]\n",
        "y_train = y_train[0:2000]\n",
        "x_test = x_test[0:500]\n",
        "y_test = y_test[0:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kSL1A5vcFp_0",
        "colab_type": "code",
        "outputId": "b343cdd5-aa99-4f95-bac0-81f22db8c811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# Resize image arrays\n",
        "x_train = resize_image_arr(x_train)\n",
        "x_test = resize_image_arr(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "khEoi_f2CxMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lEqp9NvjBSVy",
        "colab_type": "code",
        "outputId": "23bab4f3-0c79-401e-f521-d0b044ff9be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (2000, 224, 224, 3)\n",
            "2000 train samples\n",
            "500 test samples\n",
            "y_train shape: (2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v_H0TZIj2evC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJrIuWld3Awc",
        "colab_type": "code",
        "outputId": "59d18809-6af9-4740-c765-ce6c04761292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3094
        }
      },
      "cell_type": "code",
      "source": [
        "model = MobileNet(input_shape=input_shape, weights='imagenet', include_top=False, alpha=alpha)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "=================================================================\n",
            "Total params: 3,228,864\n",
            "Trainable params: 3,206,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qXD03VxCh4wa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate_on_imagenet\n",
        "\n",
        "# eval_data = model.evaluate_generator(datagen.flow_from_directory(\n",
        "#            '/root/imagenet/validation',\n",
        "#            target_size=(edge_size, edge_size),\n",
        "#            batch_size=BATCH_SIZE,\n",
        "#            class_mode='categorical'),steps=100)\n",
        "#     for i, metric_name in enumerate(base_model.metrics_names):\n",
        "#        print \"   - {0}: {1}\".format(metric_name, eval_data[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4t4nIu4B8Vt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# and a logistic layer -- 10 classes for CIFAR10\n",
        "predictions = Dense(num_classes, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CO3lmEhB8N1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=model.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ze5fDIX2hTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUTbJjyC2lw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9qbM03r1IEb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxzoH4gX_RQ7",
        "colab_type": "code",
        "outputId": "a0668791-ed66-42d9-c24e-3d8b8c8e1a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "62/62 [==============================] - 32s 515ms/step - loss: 2.4317 - categorical_accuracy: 0.0998 - top_k_categorical_accuracy: 0.4980 - val_loss: 2.4439 - val_categorical_accuracy: 0.1140 - val_top_k_categorical_accuracy: 0.5020\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 23s 367ms/step - loss: 2.4198 - categorical_accuracy: 0.0932 - top_k_categorical_accuracy: 0.4929 - val_loss: 2.3373 - val_categorical_accuracy: 0.1140 - val_top_k_categorical_accuracy: 0.5160\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 23s 364ms/step - loss: 2.4004 - categorical_accuracy: 0.0948 - top_k_categorical_accuracy: 0.5116 - val_loss: 2.3914 - val_categorical_accuracy: 0.0800 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 23s 365ms/step - loss: 2.3859 - categorical_accuracy: 0.1048 - top_k_categorical_accuracy: 0.5156 - val_loss: 2.4244 - val_categorical_accuracy: 0.1140 - val_top_k_categorical_accuracy: 0.4820\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 23s 364ms/step - loss: 2.3802 - categorical_accuracy: 0.1018 - top_k_categorical_accuracy: 0.5131 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ic2PqH6xI6Xh",
        "colab_type": "code",
        "outputId": "124dc3fb-f73c-4653-a98d-f5eb4b9cb47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 2s 4ms/step\n",
            "Test loss: 2.496279285430908\n",
            "Test accuracy: 0.098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PDGweB_z6DWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning**\n",
        "*   New dataset is small and similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n",
        "*   New dataset is large and similar to the original dataset. Since we have more data, we can have more confidence that we wonâ€™t overfit if we were to try to fine-tune through the full network.\n",
        "*   New dataset is small but very different from the original dataset. Since the data is small, it is likely best to only train a linear classifier. Since the dataset is very different, it might not be best to train the classifier form the top of the network, which contains more dataset-specific features. Instead, it might work better to train the SVM classifier from activations somewhere earlier in the network.\n",
        "*   New dataset is large and very different from the original dataset. Since the dataset is very large, we may expect that we can afford to train a ConvNet from scratch. However, in practice it is very often still beneficial to initialize with weights from a pretrained model. In this case, we would have enough data and confidence to fine-tune through the entire network.\n"
      ]
    },
    {
      "metadata": {
        "id": "4HsFlW0k0tD1",
        "colab_type": "code",
        "outputId": "9844a219-3271-4fcd-b678-5b328373cb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        }
      },
      "cell_type": "code",
      "source": [
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_4\n",
            "1 conv1_pad\n",
            "2 conv1\n",
            "3 conv1_bn\n",
            "4 conv1_relu\n",
            "5 conv_dw_1\n",
            "6 conv_dw_1_bn\n",
            "7 conv_dw_1_relu\n",
            "8 conv_pw_1\n",
            "9 conv_pw_1_bn\n",
            "10 conv_pw_1_relu\n",
            "11 conv_pad_2\n",
            "12 conv_dw_2\n",
            "13 conv_dw_2_bn\n",
            "14 conv_dw_2_relu\n",
            "15 conv_pw_2\n",
            "16 conv_pw_2_bn\n",
            "17 conv_pw_2_relu\n",
            "18 conv_dw_3\n",
            "19 conv_dw_3_bn\n",
            "20 conv_dw_3_relu\n",
            "21 conv_pw_3\n",
            "22 conv_pw_3_bn\n",
            "23 conv_pw_3_relu\n",
            "24 conv_pad_4\n",
            "25 conv_dw_4\n",
            "26 conv_dw_4_bn\n",
            "27 conv_dw_4_relu\n",
            "28 conv_pw_4\n",
            "29 conv_pw_4_bn\n",
            "30 conv_pw_4_relu\n",
            "31 conv_dw_5\n",
            "32 conv_dw_5_bn\n",
            "33 conv_dw_5_relu\n",
            "34 conv_pw_5\n",
            "35 conv_pw_5_bn\n",
            "36 conv_pw_5_relu\n",
            "37 conv_pad_6\n",
            "38 conv_dw_6\n",
            "39 conv_dw_6_bn\n",
            "40 conv_dw_6_relu\n",
            "41 conv_pw_6\n",
            "42 conv_pw_6_bn\n",
            "43 conv_pw_6_relu\n",
            "44 conv_dw_7\n",
            "45 conv_dw_7_bn\n",
            "46 conv_dw_7_relu\n",
            "47 conv_pw_7\n",
            "48 conv_pw_7_bn\n",
            "49 conv_pw_7_relu\n",
            "50 conv_dw_8\n",
            "51 conv_dw_8_bn\n",
            "52 conv_dw_8_relu\n",
            "53 conv_pw_8\n",
            "54 conv_pw_8_bn\n",
            "55 conv_pw_8_relu\n",
            "56 conv_dw_9\n",
            "57 conv_dw_9_bn\n",
            "58 conv_dw_9_relu\n",
            "59 conv_pw_9\n",
            "60 conv_pw_9_bn\n",
            "61 conv_pw_9_relu\n",
            "62 conv_dw_10\n",
            "63 conv_dw_10_bn\n",
            "64 conv_dw_10_relu\n",
            "65 conv_pw_10\n",
            "66 conv_pw_10_bn\n",
            "67 conv_pw_10_relu\n",
            "68 conv_dw_11\n",
            "69 conv_dw_11_bn\n",
            "70 conv_dw_11_relu\n",
            "71 conv_pw_11\n",
            "72 conv_pw_11_bn\n",
            "73 conv_pw_11_relu\n",
            "74 conv_pad_12\n",
            "75 conv_dw_12\n",
            "76 conv_dw_12_bn\n",
            "77 conv_dw_12_relu\n",
            "78 conv_pw_12\n",
            "79 conv_pw_12_bn\n",
            "80 conv_pw_12_relu\n",
            "81 conv_dw_13\n",
            "82 conv_dw_13_bn\n",
            "83 conv_dw_13_relu\n",
            "84 conv_pw_13\n",
            "85 conv_pw_13_bn\n",
            "86 conv_pw_13_relu\n",
            "87 global_average_pooling2d_4\n",
            "88 dense_7\n",
            "89 dense_8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vZC2M-SG0ukp",
        "colab_type": "code",
        "outputId": "605cbebf-878d-4323-e74e-3248c0e0cbcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "# We will finetune from add_9\n",
        "for layer in model.layers[:99]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[99:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "# Train!\n",
        "train_model = model.fit_generator(\n",
        "    datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "62/62 [==============================] - 26s 413ms/step - loss: 2.3591 - categorical_accuracy: 0.1013 - top_k_categorical_accuracy: 0.5086 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 18s 287ms/step - loss: 2.3619 - categorical_accuracy: 0.1018 - top_k_categorical_accuracy: 0.5070 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 19s 310ms/step - loss: 2.3580 - categorical_accuracy: 0.1028 - top_k_categorical_accuracy: 0.5131 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 19s 310ms/step - loss: 2.3627 - categorical_accuracy: 0.0988 - top_k_categorical_accuracy: 0.5051 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 19s 304ms/step - loss: 2.3596 - categorical_accuracy: 0.1028 - top_k_categorical_accuracy: 0.5086 - val_loss: 2.4963 - val_categorical_accuracy: 0.0980 - val_top_k_categorical_accuracy: 0.5120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-yZZXojJ0xt8",
        "colab_type": "code",
        "outputId": "0c0b758c-47d9-4428-c26f-6634a5a6a943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 2s 3ms/step\n",
            "Test loss: 2.496279285430908\n",
            "Test accuracy: 0.5120000002384186\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}